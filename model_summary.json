{
  "layers": [
    {
      "op_name": "linear_0_grad",
      "info": {},
      "data": 2244072,
      "kernel.name": "void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_128x128_32x3_tn_align4::Params)",
      "kernel.grid": [
        8,
        2,
        2
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 25152,
      "total_kernel_duration": 49537
    },
    {
      "op_name": "linear_0_grad",
      "info": {},
      "data": 2244072,
      "kernel.name": "void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 24385,
      "total_kernel_duration": 49537
    },
    {
      "op_name": "adaptive_avg_pool2d_0_grad",
      "info": {},
      "data": 6553600,
      "kernel.name": "void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)",
      "kernel.grid": [
        112,
        1,
        1
      ],
      "kernel.block": [
        1024,
        1,
        1
      ],
      "kernel.duration": 35872,
      "total_kernel_duration": 216448
    },
    {
      "op_name": "adaptive_avg_pool2d_0_grad",
      "info": {},
      "data": 6553600,
      "kernel.name": "void paddle::operators::math::KernelPool2DGrad<float, paddle::operators::math::AvgPoolGrad<float> >(int, float const*, float const*, float const*, int, int, int, int, int, int, int, int, int, int, paddle::operators::math::FastDivModForPoolingWithMoreStaff, paddle::operators::math::AvgPoolGrad<float>, bool, bool, float*, bool)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 180576,
      "total_kernel_duration": 216448
    },
    {
      "op_name": "re_lu_72_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 98977,
      "total_kernel_duration": 98977
    },
    {
      "op_name": "batch_norm_52_grad",
      "info": {},
      "data": 12853248,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 123872,
      "total_kernel_duration": 123872
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127585,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66848,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        4,
        25,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 132992,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17568,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18496,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 65601,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        32,
        1,
        3
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 145376,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "conv2d_52_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        512,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14016,
      "total_kernel_duration": 588482
    },
    {
      "op_name": "re_lu_70_grad",
      "info": {},
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25792,
      "total_kernel_duration": 25792
    },
    {
      "op_name": "batch_norm_51_grad",
      "info": {},
      "data": 3213312,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 33184,
      "total_kernel_duration": 33184
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 41088,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20096,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 230177,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17856,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18656,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 19840,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        36,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 299649,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "conv2d_51_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 39808,
      "total_kernel_duration": 687170
    },
    {
      "op_name": "re_lu_69_grad",
      "info": {},
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26816,
      "total_kernel_duration": 26816
    },
    {
      "op_name": "batch_norm_50_grad",
      "info": {},
      "data": 3213312,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 32737,
      "total_kernel_duration": 32737
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        64,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 124961,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17664,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        16,
        25,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 148736,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67392,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66464,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20960,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        16,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 138816,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        16,
        4,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 15040,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "conv2d_50_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 98496,
      "total_kernel_duration": 698529
    },
    {
      "op_name": "re_lu_68_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 95009,
      "total_kernel_duration": 95009
    },
    {
      "op_name": "batch_norm_49_grad",
      "info": {},
      "data": 12853248,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 125728,
      "total_kernel_duration": 125728
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126369,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 64448,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        4,
        25,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133120,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17664,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18624,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 65057,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        32,
        1,
        3
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 144544,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "conv2d_49_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        512,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14208,
      "total_kernel_duration": 584034
    },
    {
      "op_name": "re_lu_66_grad",
      "info": {},
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25536,
      "total_kernel_duration": 25536
    },
    {
      "op_name": "batch_norm_48_grad",
      "info": {},
      "data": 3213312,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 33696,
      "total_kernel_duration": 33696
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 40929,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 19937,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 230560,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17664,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18976,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 19712,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        36,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 298849,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "conv2d_48_grad",
      "info": {},
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 39808,
      "total_kernel_duration": 686435
    },
    {
      "op_name": "re_lu_65_grad",
      "info": {},
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26432,
      "total_kernel_duration": 26432
    },
    {
      "op_name": "batch_norm_47_grad",
      "info": {},
      "data": 3213312,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 34624,
      "total_kernel_duration": 34624
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        64,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 124928,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17216,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        16,
        25,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 148225,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67200,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66976,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20416,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        16,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 136449,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        16,
        4,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 15136,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "conv2d_47_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 98592,
      "total_kernel_duration": 695138
    },
    {
      "op_name": "re_lu_64_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 94752,
      "total_kernel_duration": 94752
    },
    {
      "op_name": "batch_norm_46_grad",
      "info": {},
      "data": 12853248,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 124577,
      "total_kernel_duration": 124577
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126336,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66113,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        4,
        25,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 132480,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18368,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 19040,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66368,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        32,
        1,
        3
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 144705,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "conv2d_46_grad",
      "info": {},
      "data": 21364736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        512,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 13856,
      "total_kernel_duration": 587266
    },
    {
      "op_name": "batch_norm_45_grad",
      "info": {},
      "data": 12853248,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 119616,
      "total_kernel_duration": 119616
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 246881,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66656,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 4480,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5120,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 3264,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5280,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        16,
        50,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 355041,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130752,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130497,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 69152,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "conv2d_45_grad",
      "info": {},
      "data": 9076736,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        8,
        16,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 296385,
      "total_kernel_duration": 1313508
    },
    {
      "op_name": "re_lu_61_grad",
      "info": {},
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 23392,
      "total_kernel_duration": 23392
    },
    {
      "op_name": "batch_norm_44_grad",
      "info": {},
      "data": 3213312,
      "kernel.name": "void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 33760,
      "total_kernel_duration": 33760
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 41632,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20256,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 3648,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4992,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 4160,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5025,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        8,
        52,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 356448,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63201,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66272,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20704,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        36,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 309505,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "conv2d_44_grad",
      "info": {},
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 39552,
      "total_kernel_duration": 935395
    },
    {
      "op_name": "re_lu_60_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 95072,
      "total_kernel_duration": 95072
    },
    {
      "op_name": "batch_norm_43_grad",
      "info": {},
      "data": 12847104,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 175969,
      "total_kernel_duration": 175969
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 64736,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 62176,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 275361,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126784,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 129985,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 69888,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        4,
        3
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 248609,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        4,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10720,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "conv2d_43_grad",
      "info": {},
      "data": 19791872,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 187424,
      "total_kernel_duration": 1175683
    },
    {
      "op_name": "re_lu_59_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 190337,
      "total_kernel_duration": 190337
    },
    {
      "op_name": "batch_norm_42_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 334049,
      "total_kernel_duration": 334049
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36033,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123904,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 141729,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31648,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35616,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127809,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 134176,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "conv2d_42_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10944,
      "total_kernel_duration": 641859
    },
    {
      "op_name": "re_lu_57_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 43936,
      "total_kernel_duration": 43936
    },
    {
      "op_name": "batch_norm_41_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89761,
      "total_kernel_duration": 89761
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14048,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31584,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        98,
        2,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 236353,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31264,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36256,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36128,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        18,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 295585,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        18,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16416,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "conv2d_41_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12448,
      "total_kernel_duration": 710082
    },
    {
      "op_name": "re_lu_56_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 47744,
      "total_kernel_duration": 47744
    },
    {
      "op_name": "batch_norm_40_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91713,
      "total_kernel_duration": 91713
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34497,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30655,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 172032,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 129921,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130400,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 37632,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 135552,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 11105,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "conv2d_40_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 187872,
      "total_kernel_duration": 869666
    },
    {
      "op_name": "re_lu_55_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 190593,
      "total_kernel_duration": 190593
    },
    {
      "op_name": "batch_norm_39_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 331329,
      "total_kernel_duration": 331329
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35872,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 124353,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 141024,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31744,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35712,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127713,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 134112,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "conv2d_39_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10784,
      "total_kernel_duration": 641314
    },
    {
      "op_name": "re_lu_53_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 44032,
      "total_kernel_duration": 44032
    },
    {
      "op_name": "batch_norm_38_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 87584,
      "total_kernel_duration": 87584
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14273,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32064,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        98,
        2,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 235904,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30655,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35968,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36129,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        18,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 295169,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        18,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16096,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "conv2d_38_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12416,
      "total_kernel_duration": 708674
    },
    {
      "op_name": "re_lu_52_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 47552,
      "total_kernel_duration": 47552
    },
    {
      "op_name": "batch_norm_37_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89152,
      "total_kernel_duration": 89152
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34944,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30592,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 171361,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130240,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130624,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 37536,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 135680,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10656,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "conv2d_37_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 187777,
      "total_kernel_duration": 869410
    },
    {
      "op_name": "re_lu_51_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 192192,
      "total_kernel_duration": 192192
    },
    {
      "op_name": "batch_norm_36_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 329281,
      "total_kernel_duration": 329281
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35936,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123840,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 140961,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31232,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35392,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 128448,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133601,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "conv2d_36_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 11008,
      "total_kernel_duration": 640418
    },
    {
      "op_name": "re_lu_49_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 44160,
      "total_kernel_duration": 44160
    },
    {
      "op_name": "batch_norm_35_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89984,
      "total_kernel_duration": 89984
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13888,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31840,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        98,
        2,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 235905,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30432,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36256,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36384,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        18,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 294817,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        18,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16320,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "conv2d_35_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12544,
      "total_kernel_duration": 708386
    },
    {
      "op_name": "re_lu_48_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 47713,
      "total_kernel_duration": 47713
    },
    {
      "op_name": "batch_norm_34_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 90528,
      "total_kernel_duration": 90528
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34464,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30816,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 171361,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130048,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 131104,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 37632,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 135873,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 11104,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "conv2d_34_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 187808,
      "total_kernel_duration": 870210
    },
    {
      "op_name": "re_lu_47_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 190593,
      "total_kernel_duration": 190593
    },
    {
      "op_name": "batch_norm_33_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 332417,
      "total_kernel_duration": 332417
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35873,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123872,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 140064,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31296,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35744,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 128097,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133824,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "conv2d_33_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10080,
      "total_kernel_duration": 638850
    },
    {
      "op_name": "re_lu_45_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 44928,
      "total_kernel_duration": 44928
    },
    {
      "op_name": "batch_norm_32_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91073,
      "total_kernel_duration": 91073
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13952,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32224,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        98,
        2,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 235777,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 29952,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36608,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36256,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        18,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 295201,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        18,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16032,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "conv2d_32_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12416,
      "total_kernel_duration": 708418
    },
    {
      "op_name": "re_lu_44_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 47584,
      "total_kernel_duration": 47584
    },
    {
      "op_name": "batch_norm_31_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89056,
      "total_kernel_duration": 89056
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35039,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30528,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 170400,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130529,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130144,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 38144,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 135776,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10657,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "conv2d_31_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 187872,
      "total_kernel_duration": 869089
    },
    {
      "op_name": "re_lu_43_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 190881,
      "total_kernel_duration": 190881
    },
    {
      "op_name": "batch_norm_30_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 331905,
      "total_kernel_duration": 331905
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36032,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123456,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 141185,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31712,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35424,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 129601,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133120,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "conv2d_30_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10528,
      "total_kernel_duration": 641058
    },
    {
      "op_name": "re_lu_41_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 43808,
      "total_kernel_duration": 43808
    },
    {
      "op_name": "batch_norm_29_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89665,
      "total_kernel_duration": 89665
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14272,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32287,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        98,
        2,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 235713,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 30592,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36609,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36224,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        18,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 294625,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        18,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16064,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "conv2d_29_grad",
      "info": {},
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12447,
      "total_kernel_duration": 708833
    },
    {
      "op_name": "re_lu_40_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 47168,
      "total_kernel_duration": 47168
    },
    {
      "op_name": "batch_norm_28_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 94048,
      "total_kernel_duration": 94048
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34624,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 29952,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 171457,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130592,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130400,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 37697,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 135680,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        8,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10368,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "conv2d_28_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 189057,
      "total_kernel_duration": 869827
    },
    {
      "op_name": "re_lu_39_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 189760,
      "total_kernel_duration": 189760
    },
    {
      "op_name": "batch_norm_27_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 332897,
      "total_kernel_duration": 332897
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35872,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123552,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 142721,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31232,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 35808,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127584,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133537,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "conv2d_27_grad",
      "info": {},
      "data": 39059456,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        2,
        8,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 10464,
      "total_kernel_duration": 640770
    },
    {
      "op_name": "batch_norm_26_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 329505,
      "total_kernel_duration": 329505
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 64928,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 125344,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 4384,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5216,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 3680,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 10144,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        8,
        196,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 414114,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 253376,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 253537,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 133760,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        16,
        1,
        5
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 303458,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "conv2d_26_grad",
      "info": {},
      "data": 16318464,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        256,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14784,
      "total_kernel_duration": 1586725
    },
    {
      "op_name": "re_lu_36_grad",
      "info": {},
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 44544,
      "total_kernel_duration": 44544
    },
    {
      "op_name": "batch_norm_25_grad",
      "info": {},
      "data": 6423552,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 89088,
      "total_kernel_duration": 89088
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14368,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31584,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 5120,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5056,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 4512,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7744,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        4,
        196,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 389153,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122657,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 131360,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 37728,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        18,
        2,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 302273,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "conv2d_25_grad",
      "info": {},
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12576,
      "total_kernel_duration": 1064131
    },
    {
      "op_name": "re_lu_35_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 187105,
      "total_kernel_duration": 187105
    },
    {
      "op_name": "batch_norm_24_grad",
      "info": {},
      "data": 25691136,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 375009,
      "total_kernel_duration": 375009
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 19712,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123008,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 304257,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 251073,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 254337,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130432,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        4,
        2,
        13
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 252897,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)",
      "kernel.grid": [
        4,
        2,
        4
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 14816,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "conv2d_24_grad",
      "info": {},
      "data": 38666240,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        100352,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 374401,
      "total_kernel_duration": 1724933
    },
    {
      "op_name": "re_lu_34_grad",
      "info": {},
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 378849,
      "total_kernel_duration": 378849
    },
    {
      "op_name": "batch_norm_23_grad",
      "info": {},
      "data": 51382272,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 729954,
      "total_kernel_duration": 729954
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12640,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 248129,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 180161,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63424,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 69664,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 254145,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 185632,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "conv2d_23_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10592,
      "total_kernel_duration": 1024387
    },
    {
      "op_name": "re_lu_32_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 90145,
      "total_kernel_duration": 90145
    },
    {
      "op_name": "batch_norm_22_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 199744,
      "total_kernel_duration": 199744
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7520,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61376,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 226529,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63712,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67809,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66528,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        5,
        21
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 296257,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        9,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14752,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "conv2d_22_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6496,
      "total_kernel_duration": 810979
    },
    {
      "op_name": "re_lu_31_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91488,
      "total_kernel_duration": 91488
    },
    {
      "op_name": "batch_norm_21_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 199297,
      "total_kernel_duration": 199297
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12096,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61344,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 195232,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 252545,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 255361,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 69664,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        4,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 184961,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10528,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "conv2d_21_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        100352,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 376801,
      "total_kernel_duration": 1418532
    },
    {
      "op_name": "re_lu_30_grad",
      "info": {},
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 378849,
      "total_kernel_duration": 378849
    },
    {
      "op_name": "batch_norm_20_grad",
      "info": {},
      "data": 51382272,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 729378,
      "total_kernel_duration": 729378
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12832,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 246433,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 179233,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 62625,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 70080,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 254433,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 183777,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "conv2d_20_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10624,
      "total_kernel_duration": 1020037
    },
    {
      "op_name": "re_lu_28_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 90208,
      "total_kernel_duration": 90208
    },
    {
      "op_name": "batch_norm_19_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 197761,
      "total_kernel_duration": 197761
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7456,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61888,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 226401,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63936,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67072,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66849,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        5,
        21
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 296065,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        9,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14656,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "conv2d_19_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6208,
      "total_kernel_duration": 810531
    },
    {
      "op_name": "re_lu_27_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91776,
      "total_kernel_duration": 91776
    },
    {
      "op_name": "batch_norm_18_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 197568,
      "total_kernel_duration": 197568
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12064,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61953,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 193632,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 252449,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 255585,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 69536,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        4,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 181952,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10337,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "conv2d_18_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        100352,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 378145,
      "total_kernel_duration": 1415653
    },
    {
      "op_name": "re_lu_26_grad",
      "info": {},
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 380961,
      "total_kernel_duration": 380961
    },
    {
      "op_name": "batch_norm_17_grad",
      "info": {},
      "data": 51382272,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 726338,
      "total_kernel_duration": 726338
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12672,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 249313,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 180480,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 62304,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 70561,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 253568,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 184865,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "conv2d_17_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10720,
      "total_kernel_duration": 1024483
    },
    {
      "op_name": "re_lu_24_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 90752,
      "total_kernel_duration": 90752
    },
    {
      "op_name": "batch_norm_16_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 197793,
      "total_kernel_duration": 197793
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7488,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61536,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 225921,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63968,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67456,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66432,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        5,
        21
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 295297,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        9,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 14656,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "conv2d_16_grad",
      "info": {},
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6464,
      "total_kernel_duration": 809218
    },
    {
      "op_name": "re_lu_23_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91329,
      "total_kernel_duration": 91329
    },
    {
      "op_name": "batch_norm_15_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 196896,
      "total_kernel_duration": 196896
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12096,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61888,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 195777,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 251553,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 255072,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68257,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        4,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 185728,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        4,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10656,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "conv2d_15_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        100352,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 377282,
      "total_kernel_duration": 1418309
    },
    {
      "op_name": "re_lu_22_grad",
      "info": {},
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 379169,
      "total_kernel_duration": 379169
    },
    {
      "op_name": "batch_norm_14_grad",
      "info": {},
      "data": 51382272,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 731267,
      "total_kernel_duration": 731267
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12864,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 248704,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 180513,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 63072,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 70240,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 253793,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 185921,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "conv2d_14_grad",
      "info": {},
      "data": 77201408,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10912,
      "total_kernel_duration": 1026019
    },
    {
      "op_name": "batch_norm_13_grad",
      "info": {},
      "data": 51382272,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 720386,
      "total_kernel_duration": 720386
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20224,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 245857,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 5024,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4864,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 3904,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 25376,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        4,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 554977,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 491745,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 503105,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256385,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        2,
        2,
        27
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 267617,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "conv2d_13_grad",
      "info": {},
      "data": 32178176,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        128,
        2,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 16128,
      "total_kernel_duration": 2395206
    },
    {
      "op_name": "re_lu_19_grad",
      "info": {},
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 91520,
      "total_kernel_duration": 91520
    },
    {
      "op_name": "batch_norm_12_grad",
      "info": {},
      "data": 12845568,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 198241,
      "total_kernel_duration": 198241
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7616,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 61856,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 4384,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5120,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        1,
        1
      ],
      "kernel.block": [
        1,
        1,
        1
      ],
      "kernel.duration": 4000,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        10,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 15936,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        2,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 490722,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 247424,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 255457,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 70784,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)",
      "kernel.grid": [
        9,
        1,
        12
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 307713,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "conv2d_12_grad",
      "info": {},
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6495,
      "total_kernel_duration": 1477507
    },
    {
      "op_name": "re_lu_18_grad",
      "info": {},
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 372737,
      "total_kernel_duration": 372737
    },
    {
      "op_name": "batch_norm_11_grad",
      "info": {},
      "data": 51380736,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 748643,
      "total_kernel_duration": 748643
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 8576,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 247393,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)",
      "kernel.grid": [
        2,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 436577,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 494817,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 646466,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 254209,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        2,
        52
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 394817,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        32,
        2,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 12288,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "conv2d_11_grad",
      "info": {},
      "data": 77103104,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        200704,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 761123,
      "total_kernel_duration": 3256266
    },
    {
      "op_name": "re_lu_17_grad",
      "info": {},
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 753730,
      "total_kernel_duration": 753730
    },
    {
      "op_name": "batch_norm_10_grad",
      "info": {},
      "data": 102761472,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1456836,
      "total_kernel_duration": 1456836
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4288,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3744,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 694754,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123040,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 504066,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        2,
        1,
        46
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 345089,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "conv2d_10_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10592,
      "total_kernel_duration": 1685573
    },
    {
      "op_name": "re_lu_15_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 178624,
      "total_kernel_duration": 178624
    },
    {
      "op_name": "batch_norm_9_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 491074,
      "total_kernel_duration": 491074
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5792,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122176,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 413633,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122912,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 132032,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 135969,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        3,
        72
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 432385,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        16,
        5,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 17248,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "conv2d_9_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4800,
      "total_kernel_duration": 1386947
    },
    {
      "op_name": "re_lu_14_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 183009,
      "total_kernel_duration": 183009
    },
    {
      "op_name": "batch_norm_8_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 493409,
      "total_kernel_duration": 493409
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4096,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3744,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 733090,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 499490,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 133312,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 333121,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)",
      "kernel.grid": [
        4,
        1,
        2
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 15904,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "conv2d_8_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        200704,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 760899,
      "total_kernel_duration": 2483656
    },
    {
      "op_name": "re_lu_13_grad",
      "info": {},
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 755330,
      "total_kernel_duration": 755330
    },
    {
      "op_name": "batch_norm_7_grad",
      "info": {},
      "data": 102761472,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1450053,
      "total_kernel_duration": 1450053
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4224,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3744,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 694274,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122177,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 502017,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        2,
        1,
        46
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 344001,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "conv2d_7_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10368,
      "total_kernel_duration": 1680805
    },
    {
      "op_name": "re_lu_11_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 179296,
      "total_kernel_duration": 179296
    },
    {
      "op_name": "batch_norm_6_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 494466,
      "total_kernel_duration": 494466
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5760,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123072,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 415394,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122912,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 131265,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 135328,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        3,
        72
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 431905,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        16,
        5,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 17344,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "conv2d_6_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4832,
      "total_kernel_duration": 1387812
    },
    {
      "op_name": "re_lu_10_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 183105,
      "total_kernel_duration": 183105
    },
    {
      "op_name": "batch_norm_5_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 493697,
      "total_kernel_duration": 493697
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4256,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3744,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 734179,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 499777,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134144,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)",
      "kernel.grid": [
        4,
        1,
        27
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 333825,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)",
      "kernel.grid": [
        4,
        1,
        2
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 16513,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "conv2d_5_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        200704,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 760418,
      "total_kernel_duration": 2486856
    },
    {
      "op_name": "re_lu_9_grad",
      "info": {},
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 755010,
      "total_kernel_duration": 755010
    },
    {
      "op_name": "batch_norm_4_grad",
      "info": {},
      "data": 102761472,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1456196,
      "total_kernel_duration": 1456196
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4064,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3392,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 693730,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 121793,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 503137,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        2,
        1,
        46
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 342305,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "conv2d_4_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10656,
      "total_kernel_duration": 1679077
    },
    {
      "op_name": "batch_norm_3_grad",
      "info": {},
      "data": 102761472,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1444932,
      "total_kernel_duration": 1444932
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3840,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3040,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 692899,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 123232,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 503969,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        2,
        1,
        46
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 343841,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "conv2d_3_grad",
      "info": {},
      "data": 64241664,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 10624,
      "total_kernel_duration": 1681445
    },
    {
      "op_name": "re_lu_6_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 179265,
      "total_kernel_duration": 179265
    },
    {
      "op_name": "batch_norm_2_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 489890,
      "total_kernel_duration": 489890
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5792,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122657,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 414273,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122592,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 130849,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134720,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        3,
        72
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 432290,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        16,
        5,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 17184,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "conv2d_2_grad",
      "info": {},
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4832,
      "total_kernel_duration": 1385189
    },
    {
      "op_name": "re_lu_5_grad",
      "info": {},
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 183552,
      "total_kernel_duration": 183552
    },
    {
      "op_name": "batch_norm_1_grad",
      "info": {},
      "data": 25690368,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 495074,
      "total_kernel_duration": 495074
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4064,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",
      "kernel.grid": [
        2,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3360,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "ampere_scudnn_128x64_stridedB_interior_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 193120,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 128193,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 128096,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 32, 64> >, false, 5> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 32, 64> >, false, 5>::Params)",
      "kernel.grid": [
        2,
        1,
        46
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 193153,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "conv2d_1_grad",
      "info": {},
      "data": 25694208,
      "kernel.name": "void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)",
      "kernel.grid": [
        50176,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 183520,
      "total_kernel_duration": 833506
    },
    {
      "op_name": "max_pool2d_0_grad",
      "info": {},
      "data": 64225280,
      "kernel.name": "void cudnn::ops::scalePackedTensor_kernel<float, float>(long, float*, float)",
      "kernel.grid": [
        65535,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 223681,
      "total_kernel_duration": 1337412
    },
    {
      "op_name": "max_pool2d_0_grad",
      "info": {},
      "data": 64225280,
      "kernel.name": "void cudnn::ops::pooling_bw_kernel_max<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)1>, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)",
      "kernel.grid": [
        37,
        16,
        64
      ],
      "kernel.block": [
        255,
        1,
        1
      ],
      "kernel.duration": 1113731,
      "total_kernel_duration": 1337412
    },
    {
      "op_name": "re_lu_4_grad",
      "info": {},
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 749698,
      "total_kernel_duration": 749698
    },
    {
      "op_name": "batch_norm_0_grad",
      "info": {},
      "data": 102760704,
      "kernel.name": "void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1929990,
      "total_kernel_duration": 1929990
    },
    {
      "op_name": "conv2d_0_grad",
      "info": {},
      "data": 61023424,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1568,
        1,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 440449,
      "total_kernel_duration": 1573988
    },
    {
      "op_name": "conv2d_0_grad",
      "info": {},
      "data": 61023424,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        392,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 518817,
      "total_kernel_duration": 1573988
    },
    {
      "op_name": "conv2d_0_grad",
      "info": {},
      "data": 61023424,
      "kernel.name": "_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE",
      "kernel.grid": [
        1,
        1,
        107
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 592322,
      "total_kernel_duration": 1573988
    },
    {
      "op_name": "conv2d_0_grad",
      "info": {},
      "data": 61023424,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",
      "kernel.grid": [
        16,
        2,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 17664,
      "total_kernel_duration": 1573988
    },
    {
      "op_name": "conv2d_0_grad",
      "info": {},
      "data": 61023424,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        1,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4736,
      "total_kernel_duration": 1573988
    },
    {
      "op_name": "conv2d_0",
      "info": {
        "input_shape": [
          64,
          3,
          224,
          224
        ],
        "output_shape": [
          64,
          64,
          112,
          112
        ],
        "params": 9408,
        "flops": 7552892928
      },
      "data": 61023424,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<false, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        50,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 4159,
      "total_kernel_duration": 1681892
    },
    {
      "op_name": "conv2d_0",
      "info": {
        "input_shape": [
          64,
          3,
          224,
          224
        ],
        "output_shape": [
          64,
          64,
          112,
          112
        ],
        "params": 9408,
        "flops": 7552892928
      },
      "data": 61023424,
      "kernel.name": "ampere_scudnn_128x64_relu_medium_nn_v1",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 1677733,
      "total_kernel_duration": 1681892
    },
    {
      "op_name": "batch_norm_0",
      "info": {
        "input_shape": [
          64,
          64,
          112,
          112
        ],
        "output_shape": [
          64,
          64,
          112,
          112
        ],
        "params": 256,
        "flops": 102760448
      },
      "data": 102760704,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1681222,
      "total_kernel_duration": 1681222
    },
    {
      "op_name": "re_lu_4",
      "info": {
        "input_shape": [
          64,
          64,
          112,
          112
        ],
        "output_shape": [
          64,
          64,
          112,
          112
        ],
        "params": 0,
        "flops": 0
      },
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 489409,
      "total_kernel_duration": 489409
    },
    {
      "op_name": "max_pool2d_0",
      "info": {
        "input_shape": [
          64,
          64,
          112,
          112
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 64225280,
      "kernel.name": "void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)1>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)",
      "kernel.grid": [
        37,
        16,
        64
      ],
      "kernel.block": [
        255,
        1,
        1
      ],
      "kernel.duration": 560578,
      "total_kernel_duration": 560578
    },
    {
      "op_name": "conv2d_1",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 4096,
        "flops": 822083584
      },
      "data": 25694208,
      "kernel.name": "void cask_cudnn::computeOffsetsKernel<false, false>(cask_cudnn::ComputeOffsetsParams)",
      "kernel.grid": [
        13,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 3776,
      "total_kernel_duration": 206432
    },
    {
      "op_name": "conv2d_1",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 4096,
        "flops": 822083584
      },
      "data": 25694208,
      "kernel.name": "ampere_scudnn_128x64_relu_medium_nn_v1",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 202656,
      "total_kernel_duration": 206432
    },
    {
      "op_name": "batch_norm_1",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 429570,
      "total_kernel_duration": 429570
    },
    {
      "op_name": "re_lu_5",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121792,
      "total_kernel_duration": 121792
    },
    {
      "op_name": "conv2d_2",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 129088,
      "total_kernel_duration": 603042
    },
    {
      "op_name": "conv2d_2",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5568,
      "total_kernel_duration": 603042
    },
    {
      "op_name": "conv2d_2",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 468386,
      "total_kernel_duration": 603042
    },
    {
      "op_name": "batch_norm_2",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 426529,
      "total_kernel_duration": 426529
    },
    {
      "op_name": "re_lu_6",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121440,
      "total_kernel_duration": 121440
    },
    {
      "op_name": "conv2d_3",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 129632,
      "total_kernel_duration": 519874
    },
    {
      "op_name": "conv2d_3",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6656,
      "total_kernel_duration": 519874
    },
    {
      "op_name": "conv2d_3",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 383586,
      "total_kernel_duration": 519874
    },
    {
      "op_name": "batch_norm_3",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 1024,
        "flops": 102760448
      },
      "data": 102761472,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1101507,
      "total_kernel_duration": 1101507
    },
    {
      "op_name": "conv2d_4",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127072,
      "total_kernel_duration": 503105
    },
    {
      "op_name": "conv2d_4",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6592,
      "total_kernel_duration": 503105
    },
    {
      "op_name": "conv2d_4",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 369441,
      "total_kernel_duration": 503105
    },
    {
      "op_name": "batch_norm_4",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 1024,
        "flops": 102760448
      },
      "data": 102761472,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1104292,
      "total_kernel_duration": 1104292
    },
    {
      "op_name": "re_lu_9",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 490402,
      "total_kernel_duration": 490402
    },
    {
      "op_name": "conv2d_5",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 504130,
      "total_kernel_duration": 888387
    },
    {
      "op_name": "conv2d_5",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6560,
      "total_kernel_duration": 888387
    },
    {
      "op_name": "conv2d_5",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 377697,
      "total_kernel_duration": 888387
    },
    {
      "op_name": "batch_norm_5",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 423041,
      "total_kernel_duration": 423041
    },
    {
      "op_name": "re_lu_10",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121665,
      "total_kernel_duration": 121665
    },
    {
      "op_name": "conv2d_6",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 132896,
      "total_kernel_duration": 601121
    },
    {
      "op_name": "conv2d_6",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5472,
      "total_kernel_duration": 601121
    },
    {
      "op_name": "conv2d_6",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 462753,
      "total_kernel_duration": 601121
    },
    {
      "op_name": "batch_norm_6",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 430178,
      "total_kernel_duration": 430178
    },
    {
      "op_name": "re_lu_11",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121120,
      "total_kernel_duration": 121120
    },
    {
      "op_name": "conv2d_7",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 131744,
      "total_kernel_duration": 521314
    },
    {
      "op_name": "conv2d_7",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6689,
      "total_kernel_duration": 521314
    },
    {
      "op_name": "conv2d_7",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 382881,
      "total_kernel_duration": 521314
    },
    {
      "op_name": "batch_norm_7",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 1024,
        "flops": 102760448
      },
      "data": 102761472,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1101891,
      "total_kernel_duration": 1101891
    },
    {
      "op_name": "re_lu_13",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 491073,
      "total_kernel_duration": 491073
    },
    {
      "op_name": "conv2d_8",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 504897,
      "total_kernel_duration": 884546
    },
    {
      "op_name": "conv2d_8",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6944,
      "total_kernel_duration": 884546
    },
    {
      "op_name": "conv2d_8",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 372705,
      "total_kernel_duration": 884546
    },
    {
      "op_name": "batch_norm_8",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 422690,
      "total_kernel_duration": 422690
    },
    {
      "op_name": "re_lu_14",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121600,
      "total_kernel_duration": 121600
    },
    {
      "op_name": "conv2d_9",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 131393,
      "total_kernel_duration": 602978
    },
    {
      "op_name": "conv2d_9",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 5663,
      "total_kernel_duration": 602978
    },
    {
      "op_name": "conv2d_9",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 36864,
        "flops": 7398752256
      },
      "data": 25726976,
      "kernel.name": "void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)",
      "kernel.grid": [
        1,
        784,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 465922,
      "total_kernel_duration": 602978
    },
    {
      "op_name": "batch_norm_9",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 256,
        "flops": 25690112
      },
      "data": 25690368,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        64,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 425889,
      "total_kernel_duration": 425889
    },
    {
      "op_name": "re_lu_15",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          64,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121664,
      "total_kernel_duration": 121664
    },
    {
      "op_name": "conv2d_10",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        2,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 132033,
      "total_kernel_duration": 518850
    },
    {
      "op_name": "conv2d_10",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        2,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 6592,
      "total_kernel_duration": 518850
    },
    {
      "op_name": "conv2d_10",
      "info": {
        "input_shape": [
          64,
          64,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 16384,
        "flops": 3288334336
      },
      "data": 64241664,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 380225,
      "total_kernel_duration": 518850
    },
    {
      "op_name": "batch_norm_10",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 1024,
        "flops": 102760448
      },
      "data": 102761472,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 1102467,
      "total_kernel_duration": 1102467
    },
    {
      "op_name": "re_lu_17",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          256,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 102760448,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        25088,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 492865,
      "total_kernel_duration": 492865
    },
    {
      "op_name": "conv2d_11",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          56,
          56
        ],
        "params": 32768,
        "flops": 6576668672
      },
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 504354,
      "total_kernel_duration": 923843
    },
    {
      "op_name": "conv2d_11",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          56,
          56
        ],
        "params": 32768,
        "flops": 6576668672
      },
      "data": 77103104,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 8800,
      "total_kernel_duration": 923843
    },
    {
      "op_name": "conv2d_11",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          56,
          56
        ],
        "params": 32768,
        "flops": 6576668672
      },
      "data": 77103104,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        1568,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 410689,
      "total_kernel_duration": 923843
    },
    {
      "op_name": "batch_norm_11",
      "info": {
        "input_shape": [
          64,
          128,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          56,
          56
        ],
        "params": 512,
        "flops": 51380224
      },
      "data": 51380736,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 540161,
      "total_kernel_duration": 540161
    },
    {
      "op_name": "re_lu_18",
      "info": {
        "input_shape": [
          64,
          128,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          56,
          56
        ],
        "params": 0,
        "flops": 0
      },
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 245281,
      "total_kernel_duration": 245281
    },
    {
      "op_name": "conv2d_12",
      "info": {
        "input_shape": [
          64,
          128,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256513,
      "total_kernel_duration": 560194
    },
    {
      "op_name": "conv2d_12",
      "info": {
        "input_shape": [
          64,
          128,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 32260096,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7584,
      "total_kernel_duration": 560194
    },
    {
      "op_name": "conv2d_12",
      "info": {
        "input_shape": [
          64,
          128,
          56,
          56
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 32260096,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 296097,
      "total_kernel_duration": 560194
    },
    {
      "op_name": "batch_norm_12",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 142400,
      "total_kernel_duration": 142400
    },
    {
      "op_name": "re_lu_19",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61345,
      "total_kernel_duration": 61345
    },
    {
      "op_name": "conv2d_13",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68129,
      "total_kernel_duration": 307969
    },
    {
      "op_name": "conv2d_13",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12768,
      "total_kernel_duration": 307969
    },
    {
      "op_name": "conv2d_13",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 227072,
      "total_kernel_duration": 307969
    },
    {
      "op_name": "batch_norm_13",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 2048,
        "flops": 51380224
      },
      "data": 51382272,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 501282,
      "total_kernel_duration": 501282
    },
    {
      "op_name": "conv2d_14",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        98,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 497921,
      "total_kernel_duration": 837891
    },
    {
      "op_name": "conv2d_14",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 77201408,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20929,
      "total_kernel_duration": 837891
    },
    {
      "op_name": "conv2d_14",
      "info": {
        "input_shape": [
          64,
          256,
          56,
          56
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 77201408,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 319041,
      "total_kernel_duration": 837891
    },
    {
      "op_name": "batch_norm_14",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 2048,
        "flops": 51380224
      },
      "data": 51382272,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 496353,
      "total_kernel_duration": 496353
    },
    {
      "op_name": "re_lu_22",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 245857,
      "total_kernel_duration": 245857
    },
    {
      "op_name": "conv2d_15",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256289,
      "total_kernel_duration": 489217
    },
    {
      "op_name": "conv2d_15",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12096,
      "total_kernel_duration": 489217
    },
    {
      "op_name": "conv2d_15",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 220832,
      "total_kernel_duration": 489217
    },
    {
      "op_name": "batch_norm_15",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 142785,
      "total_kernel_duration": 142785
    },
    {
      "op_name": "re_lu_23",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61024,
      "total_kernel_duration": 61024
    },
    {
      "op_name": "conv2d_16",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68704,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "conv2d_16",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7520,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "conv2d_16",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 269345,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "batch_norm_16",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 147616,
      "total_kernel_duration": 147616
    },
    {
      "op_name": "re_lu_24",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61153,
      "total_kernel_duration": 61153
    },
    {
      "op_name": "conv2d_17",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68000,
      "total_kernel_duration": 309153
    },
    {
      "op_name": "conv2d_17",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12576,
      "total_kernel_duration": 309153
    },
    {
      "op_name": "conv2d_17",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 228577,
      "total_kernel_duration": 309153
    },
    {
      "op_name": "batch_norm_17",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 2048,
        "flops": 51380224
      },
      "data": 51382272,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 496225,
      "total_kernel_duration": 496225
    },
    {
      "op_name": "re_lu_26",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 246881,
      "total_kernel_duration": 246881
    },
    {
      "op_name": "conv2d_18",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256673,
      "total_kernel_duration": 490657
    },
    {
      "op_name": "conv2d_18",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12160,
      "total_kernel_duration": 490657
    },
    {
      "op_name": "conv2d_18",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 221824,
      "total_kernel_duration": 490657
    },
    {
      "op_name": "batch_norm_18",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 142145,
      "total_kernel_duration": 142145
    },
    {
      "op_name": "re_lu_27",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60928,
      "total_kernel_duration": 60928
    },
    {
      "op_name": "conv2d_19",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68384,
      "total_kernel_duration": 346465
    },
    {
      "op_name": "conv2d_19",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7520,
      "total_kernel_duration": 346465
    },
    {
      "op_name": "conv2d_19",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 270561,
      "total_kernel_duration": 346465
    },
    {
      "op_name": "batch_norm_19",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 147520,
      "total_kernel_duration": 147520
    },
    {
      "op_name": "re_lu_28",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61153,
      "total_kernel_duration": 61153
    },
    {
      "op_name": "conv2d_20",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68064,
      "total_kernel_duration": 309377
    },
    {
      "op_name": "conv2d_20",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13120,
      "total_kernel_duration": 309377
    },
    {
      "op_name": "conv2d_20",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 228193,
      "total_kernel_duration": 309377
    },
    {
      "op_name": "batch_norm_20",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 2048,
        "flops": 51380224
      },
      "data": 51382272,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 496097,
      "total_kernel_duration": 496097
    },
    {
      "op_name": "re_lu_30",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 245665,
      "total_kernel_duration": 245665
    },
    {
      "op_name": "conv2d_21",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256289,
      "total_kernel_duration": 491681
    },
    {
      "op_name": "conv2d_21",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12096,
      "total_kernel_duration": 491681
    },
    {
      "op_name": "conv2d_21",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 223296,
      "total_kernel_duration": 491681
    },
    {
      "op_name": "batch_norm_21",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 141569,
      "total_kernel_duration": 141569
    },
    {
      "op_name": "re_lu_31",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61024,
      "total_kernel_duration": 61024
    },
    {
      "op_name": "conv2d_22",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67712,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "conv2d_22",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        128
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 7872,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "conv2d_22",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 147456,
        "flops": 7398752256
      },
      "data": 12992512,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        1,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 269985,
      "total_kernel_duration": 345569
    },
    {
      "op_name": "batch_norm_22",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 512,
        "flops": 12845056
      },
      "data": 12845568,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        128,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 147201,
      "total_kernel_duration": 147201
    },
    {
      "op_name": "re_lu_32",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          128,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60832,
      "total_kernel_duration": 60832
    },
    {
      "op_name": "conv2d_23",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        4,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68224,
      "total_kernel_duration": 309985
    },
    {
      "op_name": "conv2d_23",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        4,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 12672,
      "total_kernel_duration": 309985
    },
    {
      "op_name": "conv2d_23",
      "info": {
        "input_shape": [
          64,
          128,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 65536,
        "flops": 3288334336
      },
      "data": 32178176,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        392,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 229089,
      "total_kernel_duration": 309985
    },
    {
      "op_name": "batch_norm_23",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 2048,
        "flops": 51380224
      },
      "data": 51382272,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 495969,
      "total_kernel_duration": 495969
    },
    {
      "op_name": "re_lu_34",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          512,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 51380224,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        12544,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 245249,
      "total_kernel_duration": 245249
    },
    {
      "op_name": "conv2d_24",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 256545,
      "total_kernel_duration": 653250
    },
    {
      "op_name": "conv2d_24",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 20160,
      "total_kernel_duration": 653250
    },
    {
      "op_name": "conv2d_24",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 38666240,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x256_32x3>(cutlass_tensorop_s1688fprop_optimized_tf32_128x256_32x3::Params)",
      "kernel.grid": [
        392,
        1,
        1
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 254017,
      "total_kernel_duration": 653250
    },
    {
      "op_name": "conv2d_24",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 131072,
        "flops": 6576668672
      },
      "data": 38666240,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 122528,
      "total_kernel_duration": 653250
    },
    {
      "op_name": "batch_norm_24",
      "info": {
        "input_shape": [
          64,
          256,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 1024,
        "flops": 25690112
      },
      "data": 25691136,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 275297,
      "total_kernel_duration": 275297
    },
    {
      "op_name": "re_lu_35",
      "info": {
        "input_shape": [
          64,
          256,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          28,
          28
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 120128,
      "total_kernel_duration": 120128
    },
    {
      "op_name": "conv2d_25",
      "info": {
        "input_shape": [
          64,
          256,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 132385,
      "total_kernel_duration": 428513
    },
    {
      "op_name": "conv2d_25",
      "info": {
        "input_shape": [
          64,
          256,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 16646144,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14432,
      "total_kernel_duration": 428513
    },
    {
      "op_name": "conv2d_25",
      "info": {
        "input_shape": [
          64,
          256,
          28,
          28
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 16646144,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 281696,
      "total_kernel_duration": 428513
    },
    {
      "op_name": "batch_norm_25",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60832,
      "total_kernel_duration": 60832
    },
    {
      "op_name": "re_lu_36",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26016,
      "total_kernel_duration": 26016
    },
    {
      "op_name": "conv2d_26",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32832,
      "total_kernel_duration": 253185
    },
    {
      "op_name": "conv2d_26",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36416,
      "total_kernel_duration": 253185
    },
    {
      "op_name": "conv2d_26",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 183937,
      "total_kernel_duration": 253185
    },
    {
      "op_name": "batch_norm_26",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 220544,
      "total_kernel_duration": 220544
    },
    {
      "op_name": "conv2d_27",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        25,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 250593,
      "total_kernel_duration": 592802
    },
    {
      "op_name": "conv2d_27",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 39059456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66464,
      "total_kernel_duration": 592802
    },
    {
      "op_name": "conv2d_27",
      "info": {
        "input_shape": [
          64,
          512,
          28,
          28
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 39059456,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 275745,
      "total_kernel_duration": 592802
    },
    {
      "op_name": "batch_norm_27",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 224577,
      "total_kernel_duration": 224577
    },
    {
      "op_name": "re_lu_39",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121280,
      "total_kernel_duration": 121280
    },
    {
      "op_name": "conv2d_28",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134528,
      "total_kernel_duration": 314561
    },
    {
      "op_name": "conv2d_28",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34816,
      "total_kernel_duration": 314561
    },
    {
      "op_name": "conv2d_28",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 145217,
      "total_kernel_duration": 314561
    },
    {
      "op_name": "batch_norm_28",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60096,
      "total_kernel_duration": 60096
    },
    {
      "op_name": "re_lu_40",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26272,
      "total_kernel_duration": 26272
    },
    {
      "op_name": "conv2d_29",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32064,
      "total_kernel_duration": 323905
    },
    {
      "op_name": "conv2d_29",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14336,
      "total_kernel_duration": 323905
    },
    {
      "op_name": "conv2d_29",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 277505,
      "total_kernel_duration": 323905
    },
    {
      "op_name": "batch_norm_29",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61696,
      "total_kernel_duration": 61696
    },
    {
      "op_name": "re_lu_41",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25856,
      "total_kernel_duration": 25856
    },
    {
      "op_name": "conv2d_30",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31008,
      "total_kernel_duration": 251809
    },
    {
      "op_name": "conv2d_30",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36992,
      "total_kernel_duration": 251809
    },
    {
      "op_name": "conv2d_30",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 183809,
      "total_kernel_duration": 251809
    },
    {
      "op_name": "batch_norm_30",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 222657,
      "total_kernel_duration": 222657
    },
    {
      "op_name": "re_lu_43",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 122464,
      "total_kernel_duration": 122464
    },
    {
      "op_name": "conv2d_31",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134209,
      "total_kernel_duration": 313665
    },
    {
      "op_name": "conv2d_31",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34720,
      "total_kernel_duration": 313665
    },
    {
      "op_name": "conv2d_31",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 144736,
      "total_kernel_duration": 313665
    },
    {
      "op_name": "batch_norm_31",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60384,
      "total_kernel_duration": 60384
    },
    {
      "op_name": "re_lu_44",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26529,
      "total_kernel_duration": 26529
    },
    {
      "op_name": "conv2d_32",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31712,
      "total_kernel_duration": 324449
    },
    {
      "op_name": "conv2d_32",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14464,
      "total_kernel_duration": 324449
    },
    {
      "op_name": "conv2d_32",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 278273,
      "total_kernel_duration": 324449
    },
    {
      "op_name": "batch_norm_32",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61152,
      "total_kernel_duration": 61152
    },
    {
      "op_name": "re_lu_45",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26144,
      "total_kernel_duration": 26144
    },
    {
      "op_name": "conv2d_33",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 33024,
      "total_kernel_duration": 252129
    },
    {
      "op_name": "conv2d_33",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36416,
      "total_kernel_duration": 252129
    },
    {
      "op_name": "conv2d_33",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 182689,
      "total_kernel_duration": 252129
    },
    {
      "op_name": "batch_norm_33",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 220896,
      "total_kernel_duration": 220896
    },
    {
      "op_name": "re_lu_47",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 122304,
      "total_kernel_duration": 122304
    },
    {
      "op_name": "conv2d_34",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134209,
      "total_kernel_duration": 312993
    },
    {
      "op_name": "conv2d_34",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34528,
      "total_kernel_duration": 312993
    },
    {
      "op_name": "conv2d_34",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 144256,
      "total_kernel_duration": 312993
    },
    {
      "op_name": "batch_norm_34",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60321,
      "total_kernel_duration": 60321
    },
    {
      "op_name": "re_lu_48",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25184,
      "total_kernel_duration": 25184
    },
    {
      "op_name": "conv2d_35",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32193,
      "total_kernel_duration": 322338
    },
    {
      "op_name": "conv2d_35",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14080,
      "total_kernel_duration": 322338
    },
    {
      "op_name": "conv2d_35",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 276065,
      "total_kernel_duration": 322338
    },
    {
      "op_name": "batch_norm_35",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60544,
      "total_kernel_duration": 60544
    },
    {
      "op_name": "re_lu_49",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26688,
      "total_kernel_duration": 26688
    },
    {
      "op_name": "conv2d_36",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 32768,
      "total_kernel_duration": 251872
    },
    {
      "op_name": "conv2d_36",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36096,
      "total_kernel_duration": 251872
    },
    {
      "op_name": "conv2d_36",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 183008,
      "total_kernel_duration": 251872
    },
    {
      "op_name": "batch_norm_36",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 224129,
      "total_kernel_duration": 224129
    },
    {
      "op_name": "re_lu_51",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 123392,
      "total_kernel_duration": 123392
    },
    {
      "op_name": "conv2d_37",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 134337,
      "total_kernel_duration": 314369
    },
    {
      "op_name": "conv2d_37",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34592,
      "total_kernel_duration": 314369
    },
    {
      "op_name": "conv2d_37",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 145440,
      "total_kernel_duration": 314369
    },
    {
      "op_name": "batch_norm_37",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60704,
      "total_kernel_duration": 60704
    },
    {
      "op_name": "re_lu_52",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26304,
      "total_kernel_duration": 26304
    },
    {
      "op_name": "conv2d_38",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 33761,
      "total_kernel_duration": 324993
    },
    {
      "op_name": "conv2d_38",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14911,
      "total_kernel_duration": 324993
    },
    {
      "op_name": "conv2d_38",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 276321,
      "total_kernel_duration": 324993
    },
    {
      "op_name": "batch_norm_38",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60545,
      "total_kernel_duration": 60545
    },
    {
      "op_name": "re_lu_53",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25792,
      "total_kernel_duration": 25792
    },
    {
      "op_name": "conv2d_39",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31136,
      "total_kernel_duration": 251296
    },
    {
      "op_name": "conv2d_39",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36192,
      "total_kernel_duration": 251296
    },
    {
      "op_name": "conv2d_39",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 183968,
      "total_kernel_duration": 251296
    },
    {
      "op_name": "batch_norm_39",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 223393,
      "total_kernel_duration": 223393
    },
    {
      "op_name": "re_lu_55",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 121761,
      "total_kernel_duration": 121761
    },
    {
      "op_name": "conv2d_40",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 135008,
      "total_kernel_duration": 315137
    },
    {
      "op_name": "conv2d_40",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 34880,
      "total_kernel_duration": 315137
    },
    {
      "op_name": "conv2d_40",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 145249,
      "total_kernel_duration": 315137
    },
    {
      "op_name": "batch_norm_40",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60512,
      "total_kernel_duration": 60512
    },
    {
      "op_name": "re_lu_56",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26624,
      "total_kernel_duration": 26624
    },
    {
      "op_name": "conv2d_41",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 33152,
      "total_kernel_duration": 325921
    },
    {
      "op_name": "conv2d_41",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        256
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14528,
      "total_kernel_duration": 325921
    },
    {
      "op_name": "conv2d_41",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 589824,
        "flops": 7398752256
      },
      "data": 7012352,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel",
      "kernel.grid": [
        2,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 278241,
      "total_kernel_duration": 325921
    },
    {
      "op_name": "batch_norm_41",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 1024,
        "flops": 6422528
      },
      "data": 6423552,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        256,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 60800,
      "total_kernel_duration": 60800
    },
    {
      "op_name": "re_lu_57",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          256,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 6422528,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        1568,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26209,
      "total_kernel_duration": 26209
    },
    {
      "op_name": "conv2d_42",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        8,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 31425,
      "total_kernel_duration": 252993
    },
    {
      "op_name": "conv2d_42",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        8,
        1024
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 36544,
      "total_kernel_duration": 252993
    },
    {
      "op_name": "conv2d_42",
      "info": {
        "input_shape": [
          64,
          256,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 262144,
        "flops": 3288334336
      },
      "data": 16318464,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        8,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 185024,
      "total_kernel_duration": 252993
    },
    {
      "op_name": "batch_norm_42",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 4096,
        "flops": 25690112
      },
      "data": 25694208,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        1024,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 222113,
      "total_kernel_duration": 222113
    },
    {
      "op_name": "re_lu_59",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          1024,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 25690112,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        6272,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 122625,
      "total_kernel_duration": 122625
    },
    {
      "op_name": "conv2d_43",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 133376,
      "total_kernel_duration": 450945
    },
    {
      "op_name": "conv2d_43",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 19791872,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 65057,
      "total_kernel_duration": 450945
    },
    {
      "op_name": "conv2d_43",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          14,
          14
        ],
        "params": 524288,
        "flops": 6576668672
      },
      "data": 19791872,
      "kernel.name": "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel",
      "kernel.grid": [
        4,
        98,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 252512,
      "total_kernel_duration": 450945
    },
    {
      "op_name": "batch_norm_43",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          14,
          14
        ],
        "params": 2048,
        "flops": 12845056
      },
      "data": 12847104,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 113889,
      "total_kernel_duration": 113889
    },
    {
      "op_name": "re_lu_60",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          14,
          14
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 59584,
      "total_kernel_duration": 59584
    },
    {
      "op_name": "conv2d_44",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67936,
      "total_kernel_duration": 373921
    },
    {
      "op_name": "conv2d_44",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 40736,
      "total_kernel_duration": 373921
    },
    {
      "op_name": "conv2d_44",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 10387456,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 247105,
      "total_kernel_duration": 373921
    },
    {
      "op_name": "conv2d_44",
      "info": {
        "input_shape": [
          64,
          512,
          14,
          14
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 10387456,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18144,
      "total_kernel_duration": 373921
    },
    {
      "op_name": "batch_norm_44",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2048,
        "flops": 3211264
      },
      "data": 3213312,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26592,
      "total_kernel_duration": 26592
    },
    {
      "op_name": "re_lu_61",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 11680,
      "total_kernel_duration": 11680
    },
    {
      "op_name": "conv2d_45",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13825,
      "total_kernel_duration": 340705
    },
    {
      "op_name": "conv2d_45",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126944,
      "total_kernel_duration": 340705
    },
    {
      "op_name": "conv2d_45",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 132864,
      "total_kernel_duration": 340705
    },
    {
      "op_name": "conv2d_45",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67072,
      "total_kernel_duration": 340705
    },
    {
      "op_name": "batch_norm_45",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 8192,
        "flops": 12845056
      },
      "data": 12853248,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 105984,
      "total_kernel_duration": 105984
    },
    {
      "op_name": "conv2d_46",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 2097152,
        "flops": 6576668672
      },
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        7,
        32,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126881,
      "total_kernel_duration": 679906
    },
    {
      "op_name": "conv2d_46",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 2097152,
        "flops": 6576668672
      },
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        32,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 245952,
      "total_kernel_duration": 679906
    },
    {
      "op_name": "conv2d_46",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 2097152,
        "flops": 6576668672
      },
      "data": 21364736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 240961,
      "total_kernel_duration": 679906
    },
    {
      "op_name": "conv2d_46",
      "info": {
        "input_shape": [
          64,
          1024,
          14,
          14
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 2097152,
        "flops": 6576668672
      },
      "data": 21364736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66112,
      "total_kernel_duration": 679906
    },
    {
      "op_name": "batch_norm_46",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 8192,
        "flops": 12845056
      },
      "data": 12853248,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 107553,
      "total_kernel_duration": 107553
    },
    {
      "op_name": "re_lu_64",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 63072,
      "total_kernel_duration": 63072
    },
    {
      "op_name": "conv2d_47",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 67712,
      "total_kernel_duration": 341345
    },
    {
      "op_name": "conv2d_47",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        64,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 124833,
      "total_kernel_duration": 341345
    },
    {
      "op_name": "conv2d_47",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 130560,
      "total_kernel_duration": 341345
    },
    {
      "op_name": "conv2d_47",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18240,
      "total_kernel_duration": 341345
    },
    {
      "op_name": "batch_norm_47",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2048,
        "flops": 3211264
      },
      "data": 3213312,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 26592,
      "total_kernel_duration": 26592
    },
    {
      "op_name": "re_lu_65",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 11744,
      "total_kernel_duration": 11744
    },
    {
      "op_name": "conv2d_48",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13888,
      "total_kernel_duration": 298561
    },
    {
      "op_name": "conv2d_48",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 40992,
      "total_kernel_duration": 298561
    },
    {
      "op_name": "conv2d_48",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 225825,
      "total_kernel_duration": 298561
    },
    {
      "op_name": "conv2d_48",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17856,
      "total_kernel_duration": 298561
    },
    {
      "op_name": "batch_norm_48",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2048,
        "flops": 3211264
      },
      "data": 3213312,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25440,
      "total_kernel_duration": 25440
    },
    {
      "op_name": "re_lu_66",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 11104,
      "total_kernel_duration": 11104
    },
    {
      "op_name": "conv2d_49",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 14432,
      "total_kernel_duration": 341089
    },
    {
      "op_name": "conv2d_49",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 127041,
      "total_kernel_duration": 341089
    },
    {
      "op_name": "conv2d_49",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 133216,
      "total_kernel_duration": 341089
    },
    {
      "op_name": "conv2d_49",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66400,
      "total_kernel_duration": 341089
    },
    {
      "op_name": "batch_norm_49",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 8192,
        "flops": 12845056
      },
      "data": 12853248,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 105921,
      "total_kernel_duration": 105921
    },
    {
      "op_name": "re_lu_68",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 62944,
      "total_kernel_duration": 62944
    },
    {
      "op_name": "conv2d_50",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 68545,
      "total_kernel_duration": 343170
    },
    {
      "op_name": "conv2d_50",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        64,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 124577,
      "total_kernel_duration": 343170
    },
    {
      "op_name": "conv2d_50",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 131424,
      "total_kernel_duration": 343170
    },
    {
      "op_name": "conv2d_50",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 18624,
      "total_kernel_duration": 343170
    },
    {
      "op_name": "batch_norm_50",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2048,
        "flops": 3211264
      },
      "data": 3213312,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 27009,
      "total_kernel_duration": 27009
    },
    {
      "op_name": "re_lu_69",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 11551,
      "total_kernel_duration": 11551
    },
    {
      "op_name": "conv2d_51",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13920,
      "total_kernel_duration": 297281
    },
    {
      "op_name": "conv2d_51",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        512
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 40608,
      "total_kernel_duration": 297281
    },
    {
      "op_name": "conv2d_51",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        1,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 225473,
      "total_kernel_duration": 297281
    },
    {
      "op_name": "conv2d_51",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2359296,
        "flops": 7398752256
      },
      "data": 5570560,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 17280,
      "total_kernel_duration": 297281
    },
    {
      "op_name": "batch_norm_51",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 2048,
        "flops": 3211264
      },
      "data": 3213312,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        512,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 25504,
      "total_kernel_duration": 25504
    },
    {
      "op_name": "re_lu_70",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          512,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 3211264,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        784,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 11424,
      "total_kernel_duration": 11424
    },
    {
      "op_name": "conv2d_52",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        16,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 13760,
      "total_kernel_duration": 339489
    },
    {
      "op_name": "conv2d_52",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)",
      "kernel.grid": [
        1,
        16,
        2048
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 126624,
      "total_kernel_duration": 339489
    },
    {
      "op_name": "conv2d_52",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params)",
      "kernel.grid": [
        100,
        4,
        1
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 132545,
      "total_kernel_duration": 339489
    },
    {
      "op_name": "conv2d_52",
      "info": {
        "input_shape": [
          64,
          512,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 1048576,
        "flops": 3288334336
      },
      "data": 9076736,
      "kernel.name": "void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)",
      "kernel.grid": [
        2,
        64,
        64
      ],
      "kernel.block": [
        256,
        1,
        1
      ],
      "kernel.duration": 66560,
      "total_kernel_duration": 339489
    },
    {
      "op_name": "batch_norm_52",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 8192,
        "flops": 12845056
      },
      "data": 12853248,
      "kernel.name": "void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",
      "kernel.grid": [
        2048,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 106720,
      "total_kernel_duration": 106720
    },
    {
      "op_name": "re_lu_72",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          7,
          7
        ],
        "params": 0,
        "flops": 0
      },
      "data": 12845056,
      "kernel.name": "void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)",
      "kernel.grid": [
        3136,
        1,
        1
      ],
      "kernel.block": [
        512,
        1,
        1
      ],
      "kernel.duration": 61536,
      "total_kernel_duration": 61536
    },
    {
      "op_name": "adaptive_avg_pool2d_0",
      "info": {
        "input_shape": [
          64,
          2048,
          7,
          7
        ],
        "output_shape": [
          64,
          2048,
          1,
          1
        ],
        "params": 0,
        "flops": 6553600
      },
      "data": 6553600,
      "kernel.name": "void paddle::operators::ReduceAnyKernel<float, float, float, paddle::operators::CustomMean<float, float>, paddle::operators::kernel_primitives::details::DivideFunctor<float>, paddle::operators::LastDimIndexCal>(float const*, float*, paddle::operators::CustomMean<float, float>, paddle::operators::kernel_primitives::details::DivideFunctor<float>, float, int, int, bool, paddle::operators::LastDimIndexCal, paddle::operators::LastDimIndexCal)",
      "kernel.grid": [
        32768,
        1,
        1
      ],
      "kernel.block": [
        32,
        4,
        1
      ],
      "kernel.duration": 83264,
      "total_kernel_duration": 83264
    },
    {
      "op_name": "linear_0",
      "info": {
        "input_shape": [
          64,
          2048
        ],
        "output_shape": [
          64,
          1000
        ],
        "params": 2049000,
        "flops": 131072000
      },
      "data": 2244072,
      "kernel.name": "void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_32x3_nn_align4>(cutlass_80_tensorop_s1688gemm_128x128_32x3_nn_align4::Params)",
      "kernel.grid": [
        8,
        1,
        6
      ],
      "kernel.block": [
        128,
        1,
        1
      ],
      "kernel.duration": 20257,
      "total_kernel_duration": 25889
    },
    {
      "op_name": "linear_0",
      "info": {
        "input_shape": [
          64,
          2048
        ],
        "output_shape": [
          64,
          1000
        ],
        "params": 2049000,
        "flops": 131072000
      },
      "data": 2244072,
      "kernel.name": "void splitKreduce_kernel<float, float, float, float, true, false>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, void*, long, float*, int*)",
      "kernel.grid": [
        32,
        4,
        1
      ],
      "kernel.block": [
        32,
        16,
        1
      ],
      "kernel.duration": 5632,
      "total_kernel_duration": 25889
    }
  ]
}