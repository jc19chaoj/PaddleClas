,op_name,data,kernel.name,kernel.grid,kernel.block,kernel.duration,total_kernel_duration,info.input_shape,info.output_shape,info.params,info.flops
0,linear_0_grad,2244072,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_128x128_32x3_tn_align4::Params),"[8, 2, 2]","[128, 1, 1]",25152,49537,,,,
1,linear_0_grad,2244072,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params),"[256, 1, 1]","[128, 1, 1]",24385,49537,,,,
2,adaptive_avg_pool2d_0_grad,6553600,"void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)","[112, 1, 1]","[1024, 1, 1]",35872,216448,,,,
3,adaptive_avg_pool2d_0_grad,6553600,"void paddle::operators::math::KernelPool2DGrad<float, paddle::operators::math::AvgPoolGrad<float> >(int, float const*, float const*, float const*, int, int, int, int, int, int, int, int, int, int, paddle::operators::math::FastDivModForPoolingWithMoreStaff, paddle::operators::math::AvgPoolGrad<float>, bool, bool, float*, bool)","[12544, 1, 1]","[512, 1, 1]",180576,216448,,,,
4,re_lu_72_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",98977,98977,,,,
5,batch_norm_52_grad,12853248,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",123872,123872,,,,
6,conv2d_52_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",127585,588482,,,,
7,conv2d_52_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66848,588482,,,,
8,conv2d_52_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[4, 25, 1]","[128, 1, 1]",132992,588482,,,,
9,conv2d_52_grad,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17568,588482,,,,
10,conv2d_52_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18496,588482,,,,
11,conv2d_52_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",65601,588482,,,,
12,conv2d_52_grad,9076736,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[32, 1, 3]","[256, 1, 1]",145376,588482,,,,
13,conv2d_52_grad,9076736,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[512, 4, 1]","[32, 4, 1]",14016,588482,,,,
14,re_lu_70_grad,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[784, 1, 1]","[512, 1, 1]",25792,25792,,,,
15,batch_norm_51_grad,3213312,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",33184,33184,,,,
16,conv2d_51_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",41088,687170,,,,
17,conv2d_51_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",20096,687170,,,,
18,conv2d_51_grad,5570560,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[100, 1, 1]","[128, 1, 1]",230177,687170,,,,
19,conv2d_51_grad,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17856,687170,,,,
20,conv2d_51_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18656,687170,,,,
21,conv2d_51_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",19840,687170,,,,
22,conv2d_51_grad,5570560,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[36, 4, 3]","[128, 1, 1]",299649,687170,,,,
23,conv2d_51_grad,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",39808,687170,,,,
24,re_lu_69_grad,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[784, 1, 1]","[512, 1, 1]",26816,26816,,,,
25,batch_norm_50_grad,3213312,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",32737,32737,,,,
26,conv2d_50_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 64, 512]","[256, 1, 1]",124961,698529,,,,
27,conv2d_50_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17664,698529,,,,
28,conv2d_50_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[16, 25, 1]","[128, 1, 1]",148736,698529,,,,
29,conv2d_50_grad,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",67392,698529,,,,
30,conv2d_50_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66464,698529,,,,
31,conv2d_50_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",20960,698529,,,,
32,conv2d_50_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[16, 4, 3]","[128, 1, 1]",138816,698529,,,,
33,conv2d_50_grad,9076736,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[16, 4, 4]","[128, 1, 1]",15040,698529,,,,
34,conv2d_50_grad,9076736,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[25088, 1, 1]","[256, 1, 1]",98496,698529,,,,
35,re_lu_68_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",95009,95009,,,,
36,batch_norm_49_grad,12853248,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",125728,125728,,,,
37,conv2d_49_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",126369,584034,,,,
38,conv2d_49_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",64448,584034,,,,
39,conv2d_49_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[4, 25, 1]","[128, 1, 1]",133120,584034,,,,
40,conv2d_49_grad,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17664,584034,,,,
41,conv2d_49_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18624,584034,,,,
42,conv2d_49_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",65057,584034,,,,
43,conv2d_49_grad,9076736,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[32, 1, 3]","[256, 1, 1]",144544,584034,,,,
44,conv2d_49_grad,9076736,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[512, 4, 1]","[32, 4, 1]",14208,584034,,,,
45,re_lu_66_grad,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[784, 1, 1]","[512, 1, 1]",25536,25536,,,,
46,batch_norm_48_grad,3213312,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",33696,33696,,,,
47,conv2d_48_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",40929,686435,,,,
48,conv2d_48_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",19937,686435,,,,
49,conv2d_48_grad,5570560,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[100, 1, 1]","[128, 1, 1]",230560,686435,,,,
50,conv2d_48_grad,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17664,686435,,,,
51,conv2d_48_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18976,686435,,,,
52,conv2d_48_grad,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",19712,686435,,,,
53,conv2d_48_grad,5570560,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[36, 4, 3]","[128, 1, 1]",298849,686435,,,,
54,conv2d_48_grad,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",39808,686435,,,,
55,re_lu_65_grad,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[784, 1, 1]","[512, 1, 1]",26432,26432,,,,
56,batch_norm_47_grad,3213312,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",34624,34624,,,,
57,conv2d_47_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 64, 512]","[256, 1, 1]",124928,695138,,,,
58,conv2d_47_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17216,695138,,,,
59,conv2d_47_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[16, 25, 1]","[128, 1, 1]",148225,695138,,,,
60,conv2d_47_grad,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",67200,695138,,,,
61,conv2d_47_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66976,695138,,,,
62,conv2d_47_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",20416,695138,,,,
63,conv2d_47_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[16, 4, 3]","[128, 1, 1]",136449,695138,,,,
64,conv2d_47_grad,9076736,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[16, 4, 4]","[128, 1, 1]",15136,695138,,,,
65,conv2d_47_grad,9076736,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[25088, 1, 1]","[256, 1, 1]",98592,695138,,,,
66,re_lu_64_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",94752,94752,,,,
67,batch_norm_46_grad,12853248,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",124577,124577,,,,
68,conv2d_46_grad,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",126336,587266,,,,
69,conv2d_46_grad,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66113,587266,,,,
70,conv2d_46_grad,21364736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[4, 25, 1]","[128, 1, 1]",132480,587266,,,,
71,conv2d_46_grad,21364736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18368,587266,,,,
72,conv2d_46_grad,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",19040,587266,,,,
73,conv2d_46_grad,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66368,587266,,,,
74,conv2d_46_grad,21364736,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[32, 1, 3]","[256, 1, 1]",144705,587266,,,,
75,conv2d_46_grad,21364736,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[512, 4, 1]","[32, 4, 1]",13856,587266,,,,
76,batch_norm_45_grad,12853248,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",119616,119616,,,,
77,conv2d_45_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 2048]","[256, 1, 1]",246881,1313508,,,,
78,conv2d_45_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66656,1313508,,,,
79,conv2d_45_grad,9076736,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",4480,1313508,,,,
80,conv2d_45_grad,9076736,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",5120,1313508,,,,
81,conv2d_45_grad,9076736,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",3264,1313508,,,,
82,conv2d_45_grad,9076736,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",5280,1313508,,,,
83,conv2d_45_grad,9076736,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[16, 50, 1]","[256, 1, 1]",355041,1313508,,,,
84,conv2d_45_grad,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130752,1313508,,,,
85,conv2d_45_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130497,1313508,,,,
86,conv2d_45_grad,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",69152,1313508,,,,
87,conv2d_45_grad,9076736,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[8, 16, 3]","[128, 1, 1]",296385,1313508,,,,
88,re_lu_61_grad,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[784, 1, 1]","[512, 1, 1]",23392,23392,,,,
89,batch_norm_44_grad,3213312,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",33760,33760,,,,
90,conv2d_44_grad,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",41632,935395,,,,
91,conv2d_44_grad,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",20256,935395,,,,
92,conv2d_44_grad,10387456,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",3648,935395,,,,
93,conv2d_44_grad,10387456,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",4992,935395,,,,
94,conv2d_44_grad,10387456,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",4160,935395,,,,
95,conv2d_44_grad,10387456,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",5025,935395,,,,
96,conv2d_44_grad,10387456,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[8, 52, 1]","[256, 1, 1]",356448,935395,,,,
97,conv2d_44_grad,10387456,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 16, 64]","[256, 1, 1]",63201,935395,,,,
98,conv2d_44_grad,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 16, 64]","[256, 1, 1]",66272,935395,,,,
99,conv2d_44_grad,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",20704,935395,,,,
100,conv2d_44_grad,10387456,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[36, 4, 3]","[128, 1, 1]",309505,935395,,,,
101,conv2d_44_grad,10387456,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",39552,935395,,,,
102,re_lu_60_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",95072,95072,,,,
103,batch_norm_43_grad,12847104,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",175969,175969,,,,
104,conv2d_43_grad,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 512]","[256, 1, 1]",64736,1175683,,,,
105,conv2d_43_grad,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 16, 64]","[256, 1, 1]",62176,1175683,,,,
106,conv2d_43_grad,19791872,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",275361,1175683,,,,
107,conv2d_43_grad,19791872,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",126784,1175683,,,,
108,conv2d_43_grad,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",129985,1175683,,,,
109,conv2d_43_grad,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 16, 64]","[256, 1, 1]",69888,1175683,,,,
110,conv2d_43_grad,19791872,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 4, 3]","[128, 1, 1]",248609,1175683,,,,
111,conv2d_43_grad,19791872,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 4, 4]","[128, 1, 1]",10720,1175683,,,,
112,conv2d_43_grad,19791872,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",187424,1175683,,,,
113,re_lu_59_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",190337,190337,,,,
114,batch_norm_42_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",334049,334049,,,,
115,conv2d_42_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36033,641859,,,,
116,conv2d_42_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",123904,641859,,,,
117,conv2d_42_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",141729,641859,,,,
118,conv2d_42_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31648,641859,,,,
119,conv2d_42_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35616,641859,,,,
120,conv2d_42_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",127809,641859,,,,
121,conv2d_42_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",134176,641859,,,,
122,conv2d_42_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",10944,641859,,,,
123,re_lu_57_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",43936,43936,,,,
124,batch_norm_41_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89761,89761,,,,
125,conv2d_41_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14048,710082,,,,
126,conv2d_41_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31584,710082,,,,
127,conv2d_41_grad,7012352,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[98, 2, 1]","[128, 1, 1]",236353,710082,,,,
128,conv2d_41_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31264,710082,,,,
129,conv2d_41_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36256,710082,,,,
130,conv2d_41_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36128,710082,,,,
131,conv2d_41_grad,7012352,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 18, 5]","[256, 1, 1]",295585,710082,,,,
132,conv2d_41_grad,7012352,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 18, 1]","[32, 4, 1]",16416,710082,,,,
133,conv2d_41_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12448,710082,,,,
134,re_lu_56_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",47744,47744,,,,
135,batch_norm_40_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",91713,91713,,,,
136,conv2d_40_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34497,869666,,,,
137,conv2d_40_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30655,869666,,,,
138,conv2d_40_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",172032,869666,,,,
139,conv2d_40_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",129921,869666,,,,
140,conv2d_40_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130400,869666,,,,
141,conv2d_40_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",37632,869666,,,,
142,conv2d_40_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 6]","[128, 1, 1]",135552,869666,,,,
143,conv2d_40_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 4]","[128, 1, 1]",11105,869666,,,,
144,conv2d_40_grad,16318464,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",187872,869666,,,,
145,re_lu_55_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",190593,190593,,,,
146,batch_norm_39_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",331329,331329,,,,
147,conv2d_39_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",35872,641314,,,,
148,conv2d_39_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",124353,641314,,,,
149,conv2d_39_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",141024,641314,,,,
150,conv2d_39_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31744,641314,,,,
151,conv2d_39_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35712,641314,,,,
152,conv2d_39_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",127713,641314,,,,
153,conv2d_39_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",134112,641314,,,,
154,conv2d_39_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",10784,641314,,,,
155,re_lu_53_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",44032,44032,,,,
156,batch_norm_38_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",87584,87584,,,,
157,conv2d_38_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14273,708674,,,,
158,conv2d_38_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32064,708674,,,,
159,conv2d_38_grad,7012352,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[98, 2, 1]","[128, 1, 1]",235904,708674,,,,
160,conv2d_38_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30655,708674,,,,
161,conv2d_38_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35968,708674,,,,
162,conv2d_38_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36129,708674,,,,
163,conv2d_38_grad,7012352,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 18, 5]","[256, 1, 1]",295169,708674,,,,
164,conv2d_38_grad,7012352,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 18, 1]","[32, 4, 1]",16096,708674,,,,
165,conv2d_38_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12416,708674,,,,
166,re_lu_52_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",47552,47552,,,,
167,batch_norm_37_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89152,89152,,,,
168,conv2d_37_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34944,869410,,,,
169,conv2d_37_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30592,869410,,,,
170,conv2d_37_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",171361,869410,,,,
171,conv2d_37_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130240,869410,,,,
172,conv2d_37_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130624,869410,,,,
173,conv2d_37_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",37536,869410,,,,
174,conv2d_37_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 6]","[128, 1, 1]",135680,869410,,,,
175,conv2d_37_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 4]","[128, 1, 1]",10656,869410,,,,
176,conv2d_37_grad,16318464,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",187777,869410,,,,
177,re_lu_51_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",192192,192192,,,,
178,batch_norm_36_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",329281,329281,,,,
179,conv2d_36_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",35936,640418,,,,
180,conv2d_36_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",123840,640418,,,,
181,conv2d_36_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",140961,640418,,,,
182,conv2d_36_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31232,640418,,,,
183,conv2d_36_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35392,640418,,,,
184,conv2d_36_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",128448,640418,,,,
185,conv2d_36_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",133601,640418,,,,
186,conv2d_36_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",11008,640418,,,,
187,re_lu_49_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",44160,44160,,,,
188,batch_norm_35_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89984,89984,,,,
189,conv2d_35_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",13888,708386,,,,
190,conv2d_35_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31840,708386,,,,
191,conv2d_35_grad,7012352,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[98, 2, 1]","[128, 1, 1]",235905,708386,,,,
192,conv2d_35_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30432,708386,,,,
193,conv2d_35_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36256,708386,,,,
194,conv2d_35_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36384,708386,,,,
195,conv2d_35_grad,7012352,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 18, 5]","[256, 1, 1]",294817,708386,,,,
196,conv2d_35_grad,7012352,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 18, 1]","[32, 4, 1]",16320,708386,,,,
197,conv2d_35_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12544,708386,,,,
198,re_lu_48_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",47713,47713,,,,
199,batch_norm_34_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",90528,90528,,,,
200,conv2d_34_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34464,870210,,,,
201,conv2d_34_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30816,870210,,,,
202,conv2d_34_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",171361,870210,,,,
203,conv2d_34_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130048,870210,,,,
204,conv2d_34_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",131104,870210,,,,
205,conv2d_34_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",37632,870210,,,,
206,conv2d_34_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 6]","[128, 1, 1]",135873,870210,,,,
207,conv2d_34_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 4]","[128, 1, 1]",11104,870210,,,,
208,conv2d_34_grad,16318464,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",187808,870210,,,,
209,re_lu_47_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",190593,190593,,,,
210,batch_norm_33_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",332417,332417,,,,
211,conv2d_33_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",35873,638850,,,,
212,conv2d_33_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",123872,638850,,,,
213,conv2d_33_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",140064,638850,,,,
214,conv2d_33_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31296,638850,,,,
215,conv2d_33_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35744,638850,,,,
216,conv2d_33_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",128097,638850,,,,
217,conv2d_33_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",133824,638850,,,,
218,conv2d_33_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",10080,638850,,,,
219,re_lu_45_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",44928,44928,,,,
220,batch_norm_32_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",91073,91073,,,,
221,conv2d_32_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",13952,708418,,,,
222,conv2d_32_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32224,708418,,,,
223,conv2d_32_grad,7012352,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[98, 2, 1]","[128, 1, 1]",235777,708418,,,,
224,conv2d_32_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",29952,708418,,,,
225,conv2d_32_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36608,708418,,,,
226,conv2d_32_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36256,708418,,,,
227,conv2d_32_grad,7012352,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 18, 5]","[256, 1, 1]",295201,708418,,,,
228,conv2d_32_grad,7012352,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 18, 1]","[32, 4, 1]",16032,708418,,,,
229,conv2d_32_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12416,708418,,,,
230,re_lu_44_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",47584,47584,,,,
231,batch_norm_31_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89056,89056,,,,
232,conv2d_31_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",35039,869089,,,,
233,conv2d_31_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30528,869089,,,,
234,conv2d_31_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",170400,869089,,,,
235,conv2d_31_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130529,869089,,,,
236,conv2d_31_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130144,869089,,,,
237,conv2d_31_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",38144,869089,,,,
238,conv2d_31_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 6]","[128, 1, 1]",135776,869089,,,,
239,conv2d_31_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 4]","[128, 1, 1]",10657,869089,,,,
240,conv2d_31_grad,16318464,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",187872,869089,,,,
241,re_lu_43_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",190881,190881,,,,
242,batch_norm_30_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",331905,331905,,,,
243,conv2d_30_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36032,641058,,,,
244,conv2d_30_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",123456,641058,,,,
245,conv2d_30_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",141185,641058,,,,
246,conv2d_30_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31712,641058,,,,
247,conv2d_30_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35424,641058,,,,
248,conv2d_30_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",129601,641058,,,,
249,conv2d_30_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",133120,641058,,,,
250,conv2d_30_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",10528,641058,,,,
251,re_lu_41_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",43808,43808,,,,
252,batch_norm_29_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89665,89665,,,,
253,conv2d_29_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14272,708833,,,,
254,conv2d_29_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32287,708833,,,,
255,conv2d_29_grad,7012352,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[98, 2, 1]","[128, 1, 1]",235713,708833,,,,
256,conv2d_29_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",30592,708833,,,,
257,conv2d_29_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36609,708833,,,,
258,conv2d_29_grad,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",36224,708833,,,,
259,conv2d_29_grad,7012352,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 18, 5]","[256, 1, 1]",294625,708833,,,,
260,conv2d_29_grad,7012352,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 18, 1]","[32, 4, 1]",16064,708833,,,,
261,conv2d_29_grad,7012352,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12447,708833,,,,
262,re_lu_40_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",47168,47168,,,,
263,batch_norm_28_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",94048,94048,,,,
264,conv2d_28_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34624,869827,,,,
265,conv2d_28_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",29952,869827,,,,
266,conv2d_28_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[8, 98, 1]","[128, 1, 1]",171457,869827,,,,
267,conv2d_28_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130592,869827,,,,
268,conv2d_28_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",130400,869827,,,,
269,conv2d_28_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",37697,869827,,,,
270,conv2d_28_grad,16318464,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 6]","[128, 1, 1]",135680,869827,,,,
271,conv2d_28_grad,16318464,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[8, 2, 4]","[128, 1, 1]",10368,869827,,,,
272,conv2d_28_grad,16318464,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",189057,869827,,,,
273,re_lu_39_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",189760,189760,,,,
274,batch_norm_27_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",332897,332897,,,,
275,conv2d_27_grad,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",35872,640770,,,,
276,conv2d_27_grad,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",123552,640770,,,,
277,conv2d_27_grad,39059456,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 98, 1]","[128, 1, 1]",142721,640770,,,,
278,conv2d_27_grad,39059456,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31232,640770,,,,
279,conv2d_27_grad,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",35808,640770,,,,
280,conv2d_27_grad,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",127584,640770,,,,
281,conv2d_27_grad,39059456,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 6]","[128, 1, 1]",133537,640770,,,,
282,conv2d_27_grad,39059456,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[2, 8, 4]","[128, 1, 1]",10464,640770,,,,
283,batch_norm_26_grad,25694208,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[1024, 1, 1]","[512, 1, 1]",329505,329505,,,,
284,conv2d_26_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 1024]","[256, 1, 1]",64928,1586725,,,,
285,conv2d_26_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",125344,1586725,,,,
286,conv2d_26_grad,16318464,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",4384,1586725,,,,
287,conv2d_26_grad,16318464,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",5216,1586725,,,,
288,conv2d_26_grad,16318464,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",3680,1586725,,,,
289,conv2d_26_grad,16318464,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",10144,1586725,,,,
290,conv2d_26_grad,16318464,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[8, 196, 1]","[256, 1, 1]",414114,1586725,,,,
291,conv2d_26_grad,16318464,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",253376,1586725,,,,
292,conv2d_26_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",253537,1586725,,,,
293,conv2d_26_grad,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",133760,1586725,,,,
294,conv2d_26_grad,16318464,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[16, 1, 5]","[256, 1, 1]",303458,1586725,,,,
295,conv2d_26_grad,16318464,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[256, 4, 1]","[32, 4, 1]",14784,1586725,,,,
296,re_lu_36_grad,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",44544,44544,,,,
297,batch_norm_25_grad,6423552,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",89088,89088,,,,
298,conv2d_25_grad,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14368,1064131,,,,
299,conv2d_25_grad,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31584,1064131,,,,
300,conv2d_25_grad,16646144,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",5120,1064131,,,,
301,conv2d_25_grad,16646144,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",5056,1064131,,,,
302,conv2d_25_grad,16646144,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",4512,1064131,,,,
303,conv2d_25_grad,16646144,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",7744,1064131,,,,
304,conv2d_25_grad,16646144,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[4, 196, 1]","[256, 1, 1]",389153,1064131,,,,
305,conv2d_25_grad,16646144,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",122657,1064131,,,,
306,conv2d_25_grad,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",131360,1064131,,,,
307,conv2d_25_grad,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",37728,1064131,,,,
308,conv2d_25_grad,16646144,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[18, 2, 6]","[128, 1, 1]",302273,1064131,,,,
309,conv2d_25_grad,16646144,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",12576,1064131,,,,
310,re_lu_35_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",187105,187105,,,,
311,batch_norm_24_grad,25691136,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",375009,375009,,,,
312,conv2d_24_grad,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 256]","[256, 1, 1]",19712,1724933,,,,
313,conv2d_24_grad,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",123008,1724933,,,,
314,conv2d_24_grad,38666240,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[4, 392, 1]","[128, 1, 1]",304257,1724933,,,,
315,conv2d_24_grad,38666240,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",251073,1724933,,,,
316,conv2d_24_grad,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",254337,1724933,,,,
317,conv2d_24_grad,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",130432,1724933,,,,
318,conv2d_24_grad,38666240,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[4, 2, 13]","[128, 1, 1]",252897,1724933,,,,
319,conv2d_24_grad,38666240,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, true, 16, xmma_cudnn::Row, 128, 16> >, true, 4>::Params)","[4, 2, 4]","[128, 1, 1]",14816,1724933,,,,
320,conv2d_24_grad,38666240,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[100352, 1, 1]","[256, 1, 1]",374401,1724933,,,,
321,re_lu_34_grad,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",378849,378849,,,,
322,batch_norm_23_grad,51382272,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",729954,729954,,,,
323,conv2d_23_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12640,1024387,,,,
324,conv2d_23_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",248129,1024387,,,,
325,conv2d_23_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",180161,1024387,,,,
326,conv2d_23_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",63424,1024387,,,,
327,conv2d_23_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",69664,1024387,,,,
328,conv2d_23_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",254145,1024387,,,,
329,conv2d_23_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[4, 1, 27]","[128, 1, 1]",185632,1024387,,,,
330,conv2d_23_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[128, 1, 1]","[32, 4, 1]",10592,1024387,,,,
331,re_lu_32_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",90145,90145,,,,
332,batch_norm_22_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",199744,199744,,,,
333,conv2d_22_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7520,810979,,,,
334,conv2d_22_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61376,810979,,,,
335,conv2d_22_grad,12992512,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",226529,810979,,,,
336,conv2d_22_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",63712,810979,,,,
337,conv2d_22_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",67809,810979,,,,
338,conv2d_22_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",66528,810979,,,,
339,conv2d_22_grad,12992512,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 5, 21]","[256, 1, 1]",296257,810979,,,,
340,conv2d_22_grad,12992512,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 9, 1]","[32, 4, 1]",14752,810979,,,,
341,conv2d_22_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",6496,810979,,,,
342,re_lu_31_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",91488,91488,,,,
343,batch_norm_21_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",199297,199297,,,,
344,conv2d_21_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12096,1418532,,,,
345,conv2d_21_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61344,1418532,,,,
346,conv2d_21_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[1568, 1, 1]","[128, 1, 1]",195232,1418532,,,,
347,conv2d_21_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",252545,1418532,,,,
348,conv2d_21_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",255361,1418532,,,,
349,conv2d_21_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",69664,1418532,,,,
350,conv2d_21_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 4, 27]","[128, 1, 1]",184961,1418532,,,,
351,conv2d_21_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 4, 1]","[32, 4, 1]",10528,1418532,,,,
352,conv2d_21_grad,32178176,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[100352, 1, 1]","[256, 1, 1]",376801,1418532,,,,
353,re_lu_30_grad,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",378849,378849,,,,
354,batch_norm_20_grad,51382272,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",729378,729378,,,,
355,conv2d_20_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12832,1020037,,,,
356,conv2d_20_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",246433,1020037,,,,
357,conv2d_20_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",179233,1020037,,,,
358,conv2d_20_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",62625,1020037,,,,
359,conv2d_20_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",70080,1020037,,,,
360,conv2d_20_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",254433,1020037,,,,
361,conv2d_20_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[4, 1, 27]","[128, 1, 1]",183777,1020037,,,,
362,conv2d_20_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[128, 1, 1]","[32, 4, 1]",10624,1020037,,,,
363,re_lu_28_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",90208,90208,,,,
364,batch_norm_19_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",197761,197761,,,,
365,conv2d_19_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7456,810531,,,,
366,conv2d_19_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61888,810531,,,,
367,conv2d_19_grad,12992512,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",226401,810531,,,,
368,conv2d_19_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",63936,810531,,,,
369,conv2d_19_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",67072,810531,,,,
370,conv2d_19_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",66849,810531,,,,
371,conv2d_19_grad,12992512,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 5, 21]","[256, 1, 1]",296065,810531,,,,
372,conv2d_19_grad,12992512,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 9, 1]","[32, 4, 1]",14656,810531,,,,
373,conv2d_19_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",6208,810531,,,,
374,re_lu_27_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",91776,91776,,,,
375,batch_norm_18_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",197568,197568,,,,
376,conv2d_18_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12064,1415653,,,,
377,conv2d_18_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61953,1415653,,,,
378,conv2d_18_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[1568, 1, 1]","[128, 1, 1]",193632,1415653,,,,
379,conv2d_18_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",252449,1415653,,,,
380,conv2d_18_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",255585,1415653,,,,
381,conv2d_18_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",69536,1415653,,,,
382,conv2d_18_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 4, 27]","[128, 1, 1]",181952,1415653,,,,
383,conv2d_18_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 4, 1]","[32, 4, 1]",10337,1415653,,,,
384,conv2d_18_grad,32178176,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[100352, 1, 1]","[256, 1, 1]",378145,1415653,,,,
385,re_lu_26_grad,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",380961,380961,,,,
386,batch_norm_17_grad,51382272,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",726338,726338,,,,
387,conv2d_17_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12672,1024483,,,,
388,conv2d_17_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",249313,1024483,,,,
389,conv2d_17_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",180480,1024483,,,,
390,conv2d_17_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",62304,1024483,,,,
391,conv2d_17_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",70561,1024483,,,,
392,conv2d_17_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",253568,1024483,,,,
393,conv2d_17_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[4, 1, 27]","[128, 1, 1]",184865,1024483,,,,
394,conv2d_17_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[128, 1, 1]","[32, 4, 1]",10720,1024483,,,,
395,re_lu_24_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",90752,90752,,,,
396,batch_norm_16_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",197793,197793,,,,
397,conv2d_16_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7488,809218,,,,
398,conv2d_16_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61536,809218,,,,
399,conv2d_16_grad,12992512,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",225921,809218,,,,
400,conv2d_16_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",63968,809218,,,,
401,conv2d_16_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",67456,809218,,,,
402,conv2d_16_grad,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",66432,809218,,,,
403,conv2d_16_grad,12992512,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi256ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi256EEESC_NSE_INSG_ILi256ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 5, 21]","[256, 1, 1]",295297,809218,,,,
404,conv2d_16_grad,12992512,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 9, 1]","[32, 4, 1]",14656,809218,,,,
405,conv2d_16_grad,12992512,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",6464,809218,,,,
406,re_lu_23_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",91329,91329,,,,
407,batch_norm_15_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",196896,196896,,,,
408,conv2d_15_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12096,1418309,,,,
409,conv2d_15_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61888,1418309,,,,
410,conv2d_15_grad,32178176,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[1568, 1, 1]","[128, 1, 1]",195777,1418309,,,,
411,conv2d_15_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",251553,1418309,,,,
412,conv2d_15_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",255072,1418309,,,,
413,conv2d_15_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68257,1418309,,,,
414,conv2d_15_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 4, 27]","[128, 1, 1]",185728,1418309,,,,
415,conv2d_15_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 4, 1]","[32, 4, 1]",10656,1418309,,,,
416,conv2d_15_grad,32178176,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[100352, 1, 1]","[256, 1, 1]",377282,1418309,,,,
417,re_lu_22_grad,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",379169,379169,,,,
418,batch_norm_14_grad,51382272,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",731267,731267,,,,
419,conv2d_14_grad,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12864,1026019,,,,
420,conv2d_14_grad,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",248704,1026019,,,,
421,conv2d_14_grad,77201408,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x128_16x4_unity_stride::Params),"[392, 1, 1]","[128, 1, 1]",180513,1026019,,,,
422,conv2d_14_grad,77201408,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",63072,1026019,,,,
423,conv2d_14_grad,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",70240,1026019,,,,
424,conv2d_14_grad,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",253793,1026019,,,,
425,conv2d_14_grad,77201408,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[4, 1, 27]","[128, 1, 1]",185921,1026019,,,,
426,conv2d_14_grad,77201408,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[128, 1, 1]","[32, 4, 1]",10912,1026019,,,,
427,batch_norm_13_grad,51382272,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[512, 1, 1]","[512, 1, 1]",720386,720386,,,,
428,conv2d_13_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 512]","[256, 1, 1]",20224,2395206,,,,
429,conv2d_13_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",245857,2395206,,,,
430,conv2d_13_grad,32178176,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",5024,2395206,,,,
431,conv2d_13_grad,32178176,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",4864,2395206,,,,
432,conv2d_13_grad,32178176,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",3904,2395206,,,,
433,conv2d_13_grad,32178176,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 1, 1]","[256, 1, 1]",25376,2395206,,,,
434,conv2d_13_grad,32178176,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[4, 784, 1]","[256, 1, 1]",554977,2395206,,,,
435,conv2d_13_grad,32178176,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",491745,2395206,,,,
436,conv2d_13_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",503105,2395206,,,,
437,conv2d_13_grad,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",256385,2395206,,,,
438,conv2d_13_grad,32178176,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi256ELi128ELi32EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi256ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi256ELi32EEELi256ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi32ELi128EEESC_NSE_INSG_ILi128ELi32EEELi256ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi32EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi3EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi256ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[2, 2, 27]","[256, 1, 1]",267617,2395206,,,,
439,conv2d_13_grad,32178176,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[128, 2, 1]","[32, 4, 1]",16128,2395206,,,,
440,re_lu_19_grad,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",91520,91520,,,,
441,batch_norm_12_grad,12845568,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 32, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",198241,198241,,,,
442,conv2d_12_grad,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7616,1477507,,,,
443,conv2d_12_grad,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",61856,1477507,,,,
444,conv2d_12_grad,32260096,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[128, 1, 1]",4384,1477507,,,,
445,conv2d_12_grad,32260096,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",5120,1477507,,,,
446,conv2d_12_grad,32260096,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 1, 1]","[1, 1, 1]",4000,1477507,,,,
447,conv2d_12_grad,32260096,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[10, 1, 1]","[256, 1, 1]",15936,1477507,,,,
448,conv2d_12_grad,32260096,"void xmma_cudnn::implicit_gemm::strided_dgrad_indexed::kernel<xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>, false>(xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1> >, xmma_cudnn::implicit_gemm::strided_dgrad_indexed::Gmem_tile_epilogue<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[2, 784, 1]","[256, 1, 1]",490722,1477507,,,,
449,conv2d_12_grad,32260096,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 4, 64]","[256, 1, 1]",247424,1477507,,,,
450,conv2d_12_grad,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 4, 64]","[256, 1, 1]",255457,1477507,,,,
451,conv2d_12_grad,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",70784,1477507,,,,
452,conv2d_12_grad,32260096,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 128, 16> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 128, 16> >, false, 4>::Params)","[9, 1, 12]","[128, 1, 1]",307713,1477507,,,,
453,conv2d_12_grad,32260096,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",6495,1477507,,,,
454,re_lu_18_grad,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",372737,372737,,,,
455,batch_norm_11_grad,51380736,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[128, 1, 1]","[512, 1, 1]",748643,748643,,,,
456,conv2d_11_grad,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 128]","[256, 1, 1]",8576,3256266,,,,
457,conv2d_11_grad,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 4, 64]","[256, 1, 1]",247393,3256266,,,,
458,conv2d_11_grad,77103104,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_cudnn::Row, 16, 128> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 128, 128, 16, 2, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)","[2, 1568, 1]","[128, 1, 1]",436577,3256266,,,,
459,conv2d_11_grad,77103104,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",494817,3256266,,,,
460,conv2d_11_grad,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",646466,3256266,,,,
461,conv2d_11_grad,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 4, 64]","[256, 1, 1]",254209,3256266,,,,
462,conv2d_11_grad,77103104,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi128ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi128EEESC_SJ_EENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESJ_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SX_fNSF_8RowMajorENS11_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S14_SC_NSF_11ColumnMajorEfS14_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1E_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1D_Li1ENS1I_22PredicatedTileIteratorINS1I_26OutputTileOptimalThreadMapINS1I_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1M_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1H_4warp24FragmentIteratorTensorOpIS13_S17_fNS_5ArrayIfLi4ELb1EEES14_EENS1R_20TileIteratorTensorOpIS13_S17_fS14_EENS1I_18SharedLoadIteratorINS1P_18CompactedThreadMapEfLi16EEENS1H_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENSZ_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 2, 52]","[128, 1, 1]",394817,3256266,,,,
463,conv2d_11_grad,77103104,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[32, 2, 1]","[32, 4, 1]",12288,3256266,,,,
464,conv2d_11_grad,77103104,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[200704, 1, 1]","[256, 1, 1]",761123,3256266,,,,
465,re_lu_17_grad,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",753730,753730,,,,
466,batch_norm_10_grad,102761472,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",1456836,1456836,,,,
467,conv2d_10_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4288,1685573,,,,
468,conv2d_10_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3744,1685573,,,,
469,conv2d_10_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 1, 1]","[128, 1, 1]",694754,1685573,,,,
470,conv2d_10_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",123040,1685573,,,,
471,conv2d_10_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",504066,1685573,,,,
472,conv2d_10_grad,64241664,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[2, 1, 46]","[128, 1, 1]",345089,1685573,,,,
473,conv2d_10_grad,64241664,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 1, 1]","[32, 4, 1]",10592,1685573,,,,
474,re_lu_15_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",178624,178624,,,,
475,batch_norm_9_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",491074,491074,,,,
476,conv2d_9_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5792,1386947,,,,
477,conv2d_9_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122176,1386947,,,,
478,conv2d_9_grad,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",413633,1386947,,,,
479,conv2d_9_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122912,1386947,,,,
480,conv2d_9_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",132032,1386947,,,,
481,conv2d_9_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",135969,1386947,,,,
482,conv2d_9_grad,25726976,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 3, 72]","[128, 1, 1]",432385,1386947,,,,
483,conv2d_9_grad,25726976,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[16, 5, 1]","[32, 4, 1]",17248,1386947,,,,
484,conv2d_9_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",4800,1386947,,,,
485,re_lu_14_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",183009,183009,,,,
486,batch_norm_8_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",493409,493409,,,,
487,conv2d_8_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4096,2483656,,,,
488,conv2d_8_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3744,2483656,,,,
489,conv2d_8_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 4, 1]","[128, 1, 1]",733090,2483656,,,,
490,conv2d_8_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",499490,2483656,,,,
491,conv2d_8_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",133312,2483656,,,,
492,conv2d_8_grad,64241664,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)","[4, 1, 27]","[128, 1, 1]",333121,2483656,,,,
493,conv2d_8_grad,64241664,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)","[4, 1, 2]","[128, 1, 1]",15904,2483656,,,,
494,conv2d_8_grad,64241664,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[200704, 1, 1]","[256, 1, 1]",760899,2483656,,,,
495,re_lu_13_grad,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",755330,755330,,,,
496,batch_norm_7_grad,102761472,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",1450053,1450053,,,,
497,conv2d_7_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4224,1680805,,,,
498,conv2d_7_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3744,1680805,,,,
499,conv2d_7_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 1, 1]","[128, 1, 1]",694274,1680805,,,,
500,conv2d_7_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122177,1680805,,,,
501,conv2d_7_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",502017,1680805,,,,
502,conv2d_7_grad,64241664,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[2, 1, 46]","[128, 1, 1]",344001,1680805,,,,
503,conv2d_7_grad,64241664,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 1, 1]","[32, 4, 1]",10368,1680805,,,,
504,re_lu_11_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",179296,179296,,,,
505,batch_norm_6_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",494466,494466,,,,
506,conv2d_6_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5760,1387812,,,,
507,conv2d_6_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",123072,1387812,,,,
508,conv2d_6_grad,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",415394,1387812,,,,
509,conv2d_6_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122912,1387812,,,,
510,conv2d_6_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",131265,1387812,,,,
511,conv2d_6_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",135328,1387812,,,,
512,conv2d_6_grad,25726976,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 3, 72]","[128, 1, 1]",431905,1387812,,,,
513,conv2d_6_grad,25726976,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[16, 5, 1]","[32, 4, 1]",17344,1387812,,,,
514,conv2d_6_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",4832,1387812,,,,
515,re_lu_10_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",183105,183105,,,,
516,batch_norm_5_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",493697,493697,,,,
517,conv2d_5_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4256,2486856,,,,
518,conv2d_5_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3744,2486856,,,,
519,conv2d_5_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 4, 1]","[128, 1, 1]",734179,2486856,,,,
520,conv2d_5_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",499777,2486856,,,,
521,conv2d_5_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",134144,2486856,,,,
522,conv2d_5_grad,64241664,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)","[4, 1, 27]","[128, 1, 1]",333825,2486856,,,,
523,conv2d_5_grad,64241664,"void xmma_cudnn::gemm::split_k_kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 64, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 64, 64> >, false, 4>::Params)","[4, 1, 2]","[128, 1, 1]",16513,2486856,,,,
524,conv2d_5_grad,64241664,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[200704, 1, 1]","[256, 1, 1]",760418,2486856,,,,
525,re_lu_9_grad,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",755010,755010,,,,
526,batch_norm_4_grad,102761472,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",1456196,1456196,,,,
527,conv2d_4_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4064,1679077,,,,
528,conv2d_4_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3392,1679077,,,,
529,conv2d_4_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 1, 1]","[128, 1, 1]",693730,1679077,,,,
530,conv2d_4_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",121793,1679077,,,,
531,conv2d_4_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",503137,1679077,,,,
532,conv2d_4_grad,64241664,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[2, 1, 46]","[128, 1, 1]",342305,1679077,,,,
533,conv2d_4_grad,64241664,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 1, 1]","[32, 4, 1]",10656,1679077,,,,
534,batch_norm_3_grad,102761472,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[256, 1, 1]","[512, 1, 1]",1444932,1444932,,,,
535,conv2d_3_grad,64241664,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",3840,1681445,,,,
536,conv2d_3_grad,64241664,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3040,1681445,,,,
537,conv2d_3_grad,64241664,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 1, 1]","[128, 1, 1]",692899,1681445,,,,
538,conv2d_3_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",123232,1681445,,,,
539,conv2d_3_grad,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",503969,1681445,,,,
540,conv2d_3_grad,64241664,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi128ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi64EEESC_NSE_INSG_ILi64ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[2, 1, 46]","[128, 1, 1]",343841,1681445,,,,
541,conv2d_3_grad,64241664,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[64, 1, 1]","[32, 4, 1]",10624,1681445,,,,
542,re_lu_6_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",179265,179265,,,,
543,batch_norm_2_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",489890,489890,,,,
544,conv2d_2_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5792,1385189,,,,
545,conv2d_2_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122657,1385189,,,,
546,conv2d_2_grad,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::dgrad::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::dgrad::Gmem_tile_c_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 16, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false>, false>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",414273,1385189,,,,
547,conv2d_2_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",122592,1385189,,,,
548,conv2d_2_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",130849,1385189,,,,
549,conv2d_2_grad,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",134720,1385189,,,,
550,conv2d_2_grad,25726976,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 3, 72]","[128, 1, 1]",432290,1385189,,,,
551,conv2d_2_grad,25726976,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[16, 5, 1]","[32, 4, 1]",17184,1385189,,,,
552,conv2d_2_grad,25726976,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",4832,1385189,,,,
553,re_lu_5_grad,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",183552,183552,,,,
554,batch_norm_1_grad,25690368,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",495074,495074,,,,
555,conv2d_1_grad,25694208,"void cask_cudnn::computeOffsetsKernel<true, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",4064,833506,,,,
556,conv2d_1_grad,25694208,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),"[2, 1, 1]","[256, 1, 1]",3360,833506,,,,
557,conv2d_1_grad,25694208,ampere_scudnn_128x64_stridedB_interior_nn_v1,"[1568, 1, 1]","[128, 1, 1]",193120,833506,,,,
558,conv2d_1_grad,25694208,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",128193,833506,,,,
559,conv2d_1_grad,25694208,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",128096,833506,,,,
560,conv2d_1_grad,25694208,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 32, 64> >, false, 5> >(xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, 16, xmma_cudnn::Col, 64, 64> >, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, false, xmma_cudnn::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 64, 32, 64, 2, 2, 1, 1>, false, 16, xmma_cudnn::Row, 32, 64> >, false, 5>::Params)","[2, 1, 46]","[128, 1, 1]",193153,833506,,,,
561,conv2d_1_grad,25694208,"void axpy_kernel_val<float, float>(cublasAxpyParamsVal<float, float, float>)","[50176, 1, 1]","[256, 1, 1]",183520,833506,,,,
562,max_pool2d_0_grad,64225280,"void cudnn::ops::scalePackedTensor_kernel<float, float>(long, float*, float)","[65535, 1, 1]","[256, 1, 1]",223681,1337412,,,,
563,max_pool2d_0_grad,64225280,"void cudnn::ops::pooling_bw_kernel_max<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)1>, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)","[37, 16, 64]","[255, 1, 1]",1113731,1337412,,,,
564,re_lu_4_grad,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluGradFunctor<float>, 2, 4>(paddle::framework::Array<float const* restrict, 2>, float*, int, paddle::operators::CudaReluGradFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",749698,749698,,,,
565,batch_norm_0_grad,102760704,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)","[64, 1, 1]","[512, 1, 1]",1929990,1929990,,,,
566,conv2d_0_grad,61023424,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1568, 1, 64]","[256, 1, 1]",440449,1573988,,,,
567,conv2d_0_grad,61023424,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[392, 2, 64]","[256, 1, 1]",518817,1573988,,,,
568,conv2d_0_grad,61023424,_ZN13cutlass_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi256ELi16EEENS4_51Conv2dWgradOutputGradientTileAccessIteratorAnalyticINS_11MatrixShapeILi64ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_6layout16PitchLinearShapeILi64ELi16EEELi128ENSG_ILi8ELi4EEELi4EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NSF_40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESJ_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_47Conv2dWgradActivationTileAccessIteratorAnalyticINSA_ILi16ELi256EEESC_NSE_INSG_ILi256ELi16EEELi128ESI_Li4EEEEENSM_ISU_SC_NSF_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESW_Li16EEELSS_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi64ELi16EEESC_SO_SC_SZ_fNSF_8RowMajorENS13_17MmaTensorOpPolicyINSQ_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSF_11ColumnMajorEfS16_NSQ_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi256ELi8ELi1ELi1ELi1EEENS1O_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1T_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEEEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeEEEEEvNT_6ParamsE,"[1, 1, 107]","[128, 1, 1]",592322,1573988,,,,
569,conv2d_0_grad,61023424,"void cutlass_cudnn::Kernel<cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn::reduction::kernel::ReduceSplitK<cutlass_cudnn::MatrixShape<4, 128>, cutlass_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn::FloatRoundStyle)2>, cutlass_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)","[16, 2, 1]","[32, 4, 1]",17664,1573988,,,,
570,conv2d_0_grad,61023424,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 1, 64]","[256, 1, 1]",4736,1573988,,,,
571,conv2d_0,61023424,"void cask_cudnn::computeOffsetsKernel<false, false>(cask_cudnn::ComputeOffsetsParams)","[50, 1, 1]","[256, 1, 1]",4159,1681892,"[64, 3, 224, 224]","[64, 64, 112, 112]",9408.0,7552892928.0
572,conv2d_0,61023424,ampere_scudnn_128x64_relu_medium_nn_v1,"[6272, 1, 1]","[128, 1, 1]",1677733,1681892,"[64, 3, 224, 224]","[64, 64, 112, 112]",9408.0,7552892928.0
573,batch_norm_0,102760704,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",1681222,1681222,"[64, 64, 112, 112]","[64, 64, 112, 112]",256.0,102760448.0
574,re_lu_4,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",489409,489409,"[64, 64, 112, 112]","[64, 64, 112, 112]",0.0,0.0
575,max_pool2d_0,64225280,"void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)1>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)","[37, 16, 64]","[255, 1, 1]",560578,560578,"[64, 64, 112, 112]","[64, 64, 56, 56]",0.0,0.0
576,conv2d_1,25694208,"void cask_cudnn::computeOffsetsKernel<false, false>(cask_cudnn::ComputeOffsetsParams)","[13, 1, 1]","[256, 1, 1]",3776,206432,"[64, 64, 56, 56]","[64, 64, 56, 56]",4096.0,822083584.0
577,conv2d_1,25694208,ampere_scudnn_128x64_relu_medium_nn_v1,"[1568, 1, 1]","[128, 1, 1]",202656,206432,"[64, 64, 56, 56]","[64, 64, 56, 56]",4096.0,822083584.0
578,batch_norm_1,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",429570,429570,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
579,re_lu_5,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121792,121792,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
580,conv2d_2,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",129088,603042,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
581,conv2d_2,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5568,603042,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
582,conv2d_2,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",468386,603042,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
583,batch_norm_2,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",426529,426529,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
584,re_lu_6,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121440,121440,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
585,conv2d_3,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",129632,519874,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
586,conv2d_3,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 256]","[256, 1, 1]",6656,519874,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
587,conv2d_3,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 1568, 1]","[128, 1, 1]",383586,519874,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
588,batch_norm_3,102761472,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",1101507,1101507,"[64, 256, 56, 56]","[64, 256, 56, 56]",1024.0,102760448.0
589,conv2d_4,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",127072,503105,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
590,conv2d_4,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 256]","[256, 1, 1]",6592,503105,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
591,conv2d_4,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 1568, 1]","[128, 1, 1]",369441,503105,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
592,batch_norm_4,102761472,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",1104292,1104292,"[64, 256, 56, 56]","[64, 256, 56, 56]",1024.0,102760448.0
593,re_lu_9,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",490402,490402,"[64, 256, 56, 56]","[64, 256, 56, 56]",0.0,0.0
594,conv2d_5,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",504130,888387,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
595,conv2d_5,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 64]","[256, 1, 1]",6560,888387,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
596,conv2d_5,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 1568, 1]","[128, 1, 1]",377697,888387,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
597,batch_norm_5,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",423041,423041,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
598,re_lu_10,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121665,121665,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
599,conv2d_6,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",132896,601121,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
600,conv2d_6,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5472,601121,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
601,conv2d_6,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",462753,601121,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
602,batch_norm_6,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",430178,430178,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
603,re_lu_11,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121120,121120,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
604,conv2d_7,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",131744,521314,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
605,conv2d_7,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 256]","[256, 1, 1]",6689,521314,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
606,conv2d_7,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 1568, 1]","[128, 1, 1]",382881,521314,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
607,batch_norm_7,102761472,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",1101891,1101891,"[64, 256, 56, 56]","[64, 256, 56, 56]",1024.0,102760448.0
608,re_lu_13,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",491073,491073,"[64, 256, 56, 56]","[64, 256, 56, 56]",0.0,0.0
609,conv2d_8,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",504897,884546,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
610,conv2d_8,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 64]","[256, 1, 1]",6944,884546,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
611,conv2d_8,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 1568, 1]","[128, 1, 1]",372705,884546,"[64, 256, 56, 56]","[64, 64, 56, 56]",16384.0,3288334336.0
612,batch_norm_8,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",422690,422690,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
613,re_lu_14,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121600,121600,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
614,conv2d_9,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",131393,602978,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
615,conv2d_9,25726976,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 64]","[256, 1, 1]",5663,602978,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
616,conv2d_9,25726976,"void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_cudnn::implicit_gemm::fprop_indexed::Kernel_traits<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_cudnn::Row, 32, 256> >, xmma_cudnn::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, 4, xmma_cudnn::Fragment_c<xmma_cudnn::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_cudnn::Cta_tile<xmma_cudnn::Ampere, 256, 64, 32, 4, 2, 1, 1>, false> >, xmma_cudnn::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)","[1, 784, 1]","[256, 1, 1]",465922,602978,"[64, 64, 56, 56]","[64, 64, 56, 56]",36864.0,7398752256.0
617,batch_norm_9,25690368,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[64, 1, 1]","[512, 1, 1]",425889,425889,"[64, 64, 56, 56]","[64, 64, 56, 56]",256.0,25690112.0
618,re_lu_15,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121664,121664,"[64, 64, 56, 56]","[64, 64, 56, 56]",0.0,0.0
619,conv2d_10,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 2, 64]","[256, 1, 1]",132033,518850,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
620,conv2d_10,64241664,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 2, 256]","[256, 1, 1]",6592,518850,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
621,conv2d_10,64241664,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 1568, 1]","[128, 1, 1]",380225,518850,"[64, 64, 56, 56]","[64, 256, 56, 56]",16384.0,3288334336.0
622,batch_norm_10,102761472,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",1102467,1102467,"[64, 256, 56, 56]","[64, 256, 56, 56]",1024.0,102760448.0
623,re_lu_17,102760448,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[25088, 1, 1]","[512, 1, 1]",492865,492865,"[64, 256, 56, 56]","[64, 256, 56, 56]",0.0,0.0
624,conv2d_11,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",504354,923843,"[64, 256, 56, 56]","[64, 128, 56, 56]",32768.0,6576668672.0
625,conv2d_11,77103104,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 128]","[256, 1, 1]",8800,923843,"[64, 256, 56, 56]","[64, 128, 56, 56]",32768.0,6576668672.0
626,conv2d_11,77103104,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 1568, 1]","[128, 1, 1]",410689,923843,"[64, 256, 56, 56]","[64, 128, 56, 56]",32768.0,6576668672.0
627,batch_norm_11,51380736,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 128, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",540161,540161,"[64, 128, 56, 56]","[64, 128, 56, 56]",512.0,51380224.0
628,re_lu_18,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",245281,245281,"[64, 128, 56, 56]","[64, 128, 56, 56]",0.0,0.0
629,conv2d_12,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 4, 64]","[256, 1, 1]",256513,560194,"[64, 128, 56, 56]","[64, 128, 28, 28]",147456.0,7398752256.0
630,conv2d_12,32260096,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7584,560194,"[64, 128, 56, 56]","[64, 128, 28, 28]",147456.0,7398752256.0
631,conv2d_12,32260096,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[1, 392, 1]","[128, 1, 1]",296097,560194,"[64, 128, 56, 56]","[64, 128, 28, 28]",147456.0,7398752256.0
632,batch_norm_12,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",142400,142400,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
633,re_lu_19,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61345,61345,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
634,conv2d_13,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68129,307969,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
635,conv2d_13,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12768,307969,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
636,conv2d_13,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 392, 1]","[128, 1, 1]",227072,307969,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
637,batch_norm_13,51382272,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",501282,501282,"[64, 512, 28, 28]","[64, 512, 28, 28]",2048.0,51380224.0
638,conv2d_14,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[98, 8, 64]","[256, 1, 1]",497921,837891,"[64, 256, 56, 56]","[64, 512, 28, 28]",131072.0,6576668672.0
639,conv2d_14,77201408,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 512]","[256, 1, 1]",20929,837891,"[64, 256, 56, 56]","[64, 512, 28, 28]",131072.0,6576668672.0
640,conv2d_14,77201408,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 392, 1]","[128, 1, 1]",319041,837891,"[64, 256, 56, 56]","[64, 512, 28, 28]",131072.0,6576668672.0
641,batch_norm_14,51382272,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",496353,496353,"[64, 512, 28, 28]","[64, 512, 28, 28]",2048.0,51380224.0
642,re_lu_22,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",245857,245857,"[64, 512, 28, 28]","[64, 512, 28, 28]",0.0,0.0
643,conv2d_15,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",256289,489217,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
644,conv2d_15,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12096,489217,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
645,conv2d_15,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 392, 1]","[128, 1, 1]",220832,489217,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
646,batch_norm_15,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",142785,142785,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
647,re_lu_23,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61024,61024,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
648,conv2d_16,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68704,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
649,conv2d_16,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7520,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
650,conv2d_16,12992512,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[1, 392, 1]","[128, 1, 1]",269345,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
651,batch_norm_16,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",147616,147616,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
652,re_lu_24,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61153,61153,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
653,conv2d_17,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68000,309153,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
654,conv2d_17,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12576,309153,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
655,conv2d_17,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 392, 1]","[128, 1, 1]",228577,309153,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
656,batch_norm_17,51382272,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",496225,496225,"[64, 512, 28, 28]","[64, 512, 28, 28]",2048.0,51380224.0
657,re_lu_26,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",246881,246881,"[64, 512, 28, 28]","[64, 512, 28, 28]",0.0,0.0
658,conv2d_18,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",256673,490657,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
659,conv2d_18,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12160,490657,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
660,conv2d_18,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 392, 1]","[128, 1, 1]",221824,490657,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
661,batch_norm_18,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",142145,142145,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
662,re_lu_27,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",60928,60928,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
663,conv2d_19,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68384,346465,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
664,conv2d_19,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7520,346465,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
665,conv2d_19,12992512,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[1, 392, 1]","[128, 1, 1]",270561,346465,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
666,batch_norm_19,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",147520,147520,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
667,re_lu_28,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61153,61153,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
668,conv2d_20,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68064,309377,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
669,conv2d_20,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",13120,309377,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
670,conv2d_20,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 392, 1]","[128, 1, 1]",228193,309377,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
671,batch_norm_20,51382272,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",496097,496097,"[64, 512, 28, 28]","[64, 512, 28, 28]",2048.0,51380224.0
672,re_lu_30,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",245665,245665,"[64, 512, 28, 28]","[64, 512, 28, 28]",0.0,0.0
673,conv2d_21,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",256289,491681,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
674,conv2d_21,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 128]","[256, 1, 1]",12096,491681,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
675,conv2d_21,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[1, 392, 1]","[128, 1, 1]",223296,491681,"[64, 512, 28, 28]","[64, 128, 28, 28]",65536.0,3288334336.0
676,batch_norm_21,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",141569,141569,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
677,re_lu_31,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61024,61024,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
678,conv2d_22,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",67712,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
679,conv2d_22,12992512,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 128]","[256, 1, 1]",7872,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
680,conv2d_22,12992512,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[1, 392, 1]","[128, 1, 1]",269985,345569,"[64, 128, 28, 28]","[64, 128, 28, 28]",147456.0,7398752256.0
681,batch_norm_22,12845568,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[128, 1, 1]","[512, 1, 1]",147201,147201,"[64, 128, 28, 28]","[64, 128, 28, 28]",512.0,12845056.0
682,re_lu_32,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",60832,60832,"[64, 128, 28, 28]","[64, 128, 28, 28]",0.0,0.0
683,conv2d_23,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 4, 64]","[256, 1, 1]",68224,309985,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
684,conv2d_23,32178176,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 4, 512]","[256, 1, 1]",12672,309985,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
685,conv2d_23,32178176,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 392, 1]","[128, 1, 1]",229089,309985,"[64, 128, 28, 28]","[64, 512, 28, 28]",65536.0,3288334336.0
686,batch_norm_23,51382272,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",495969,495969,"[64, 512, 28, 28]","[64, 512, 28, 28]",2048.0,51380224.0
687,re_lu_34,51380224,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[12544, 1, 1]","[512, 1, 1]",245249,245249,"[64, 512, 28, 28]","[64, 512, 28, 28]",0.0,0.0
688,conv2d_24,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",256545,653250,"[64, 512, 28, 28]","[64, 256, 28, 28]",131072.0,6576668672.0
689,conv2d_24,38666240,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 256]","[256, 1, 1]",20160,653250,"[64, 512, 28, 28]","[64, 256, 28, 28]",131072.0,6576668672.0
690,conv2d_24,38666240,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x256_32x3>(cutlass_tensorop_s1688fprop_optimized_tf32_128x256_32x3::Params),"[392, 1, 1]","[256, 1, 1]",254017,653250,"[64, 512, 28, 28]","[64, 256, 28, 28]",131072.0,6576668672.0
691,conv2d_24,38666240,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",122528,653250,"[64, 512, 28, 28]","[64, 256, 28, 28]",131072.0,6576668672.0
692,batch_norm_24,25691136,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",275297,275297,"[64, 256, 28, 28]","[64, 256, 28, 28]",1024.0,25690112.0
693,re_lu_35,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",120128,120128,"[64, 256, 28, 28]","[64, 256, 28, 28]",0.0,0.0
694,conv2d_25,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 8, 64]","[256, 1, 1]",132385,428513,"[64, 256, 28, 28]","[64, 256, 14, 14]",589824.0,7398752256.0
695,conv2d_25,16646144,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14432,428513,"[64, 256, 28, 28]","[64, 256, 14, 14]",589824.0,7398752256.0
696,conv2d_25,16646144,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",281696,428513,"[64, 256, 28, 28]","[64, 256, 14, 14]",589824.0,7398752256.0
697,batch_norm_25,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60832,60832,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
698,re_lu_36,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26016,26016,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
699,conv2d_26,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32832,253185,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
700,conv2d_26,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36416,253185,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
701,conv2d_26,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",183937,253185,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
702,batch_norm_26,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",220544,220544,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
703,conv2d_27,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[25, 16, 64]","[256, 1, 1]",250593,592802,"[64, 512, 28, 28]","[64, 1024, 14, 14]",524288.0,6576668672.0
704,conv2d_27,39059456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 1024]","[256, 1, 1]",66464,592802,"[64, 512, 28, 28]","[64, 1024, 14, 14]",524288.0,6576668672.0
705,conv2d_27,39059456,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",275745,592802,"[64, 512, 28, 28]","[64, 1024, 14, 14]",524288.0,6576668672.0
706,batch_norm_27,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",224577,224577,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
707,re_lu_39,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121280,121280,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
708,conv2d_28,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",134528,314561,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
709,conv2d_28,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34816,314561,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
710,conv2d_28,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 98, 1]","[128, 1, 1]",145217,314561,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
711,batch_norm_28,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60096,60096,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
712,re_lu_40,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26272,26272,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
713,conv2d_29,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32064,323905,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
714,conv2d_29,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14336,323905,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
715,conv2d_29,7012352,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",277505,323905,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
716,batch_norm_29,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",61696,61696,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
717,re_lu_41,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",25856,25856,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
718,conv2d_30,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31008,251809,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
719,conv2d_30,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36992,251809,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
720,conv2d_30,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",183809,251809,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
721,batch_norm_30,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",222657,222657,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
722,re_lu_43,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",122464,122464,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
723,conv2d_31,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",134209,313665,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
724,conv2d_31,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34720,313665,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
725,conv2d_31,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 98, 1]","[128, 1, 1]",144736,313665,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
726,batch_norm_31,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60384,60384,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
727,re_lu_44,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26529,26529,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
728,conv2d_32,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31712,324449,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
729,conv2d_32,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14464,324449,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
730,conv2d_32,7012352,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",278273,324449,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
731,batch_norm_32,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",61152,61152,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
732,re_lu_45,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26144,26144,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
733,conv2d_33,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",33024,252129,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
734,conv2d_33,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36416,252129,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
735,conv2d_33,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",182689,252129,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
736,batch_norm_33,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",220896,220896,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
737,re_lu_47,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",122304,122304,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
738,conv2d_34,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",134209,312993,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
739,conv2d_34,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34528,312993,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
740,conv2d_34,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 98, 1]","[128, 1, 1]",144256,312993,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
741,batch_norm_34,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60321,60321,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
742,re_lu_48,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",25184,25184,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
743,conv2d_35,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32193,322338,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
744,conv2d_35,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14080,322338,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
745,conv2d_35,7012352,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",276065,322338,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
746,batch_norm_35,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60544,60544,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
747,re_lu_49,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26688,26688,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
748,conv2d_36,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",32768,251872,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
749,conv2d_36,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36096,251872,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
750,conv2d_36,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",183008,251872,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
751,batch_norm_36,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",224129,224129,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
752,re_lu_51,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",123392,123392,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
753,conv2d_37,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",134337,314369,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
754,conv2d_37,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34592,314369,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
755,conv2d_37,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 98, 1]","[128, 1, 1]",145440,314369,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
756,batch_norm_37,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60704,60704,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
757,re_lu_52,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26304,26304,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
758,conv2d_38,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",33761,324993,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
759,conv2d_38,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14911,324993,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
760,conv2d_38,7012352,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",276321,324993,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
761,batch_norm_38,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60545,60545,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
762,re_lu_53,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",25792,25792,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
763,conv2d_39,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31136,251296,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
764,conv2d_39,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36192,251296,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
765,conv2d_39,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",183968,251296,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
766,batch_norm_39,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",223393,223393,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
767,re_lu_55,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",121761,121761,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
768,conv2d_40,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",135008,315137,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
769,conv2d_40,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 256]","[256, 1, 1]",34880,315137,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
770,conv2d_40,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[2, 98, 1]","[128, 1, 1]",145249,315137,"[64, 1024, 14, 14]","[64, 256, 14, 14]",262144.0,3288334336.0
771,batch_norm_40,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60512,60512,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
772,re_lu_56,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26624,26624,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
773,conv2d_41,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",33152,325921,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
774,conv2d_41,7012352,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 256]","[256, 1, 1]",14528,325921,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
775,conv2d_41,7012352,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel,"[2, 98, 1]","[128, 1, 1]",278241,325921,"[64, 256, 14, 14]","[64, 256, 14, 14]",589824.0,7398752256.0
776,batch_norm_41,6423552,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[256, 1, 1]","[512, 1, 1]",60800,60800,"[64, 256, 14, 14]","[64, 256, 14, 14]",1024.0,6422528.0
777,re_lu_57,6422528,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[1568, 1, 1]","[512, 1, 1]",26209,26209,"[64, 256, 14, 14]","[64, 256, 14, 14]",0.0,0.0
778,conv2d_42,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 8, 64]","[256, 1, 1]",31425,252993,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
779,conv2d_42,16318464,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 8, 1024]","[256, 1, 1]",36544,252993,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
780,conv2d_42,16318464,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[8, 98, 1]","[128, 1, 1]",185024,252993,"[64, 256, 14, 14]","[64, 1024, 14, 14]",262144.0,3288334336.0
781,batch_norm_42,25694208,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[1024, 1, 1]","[512, 1, 1]",222113,222113,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",4096.0,25690112.0
782,re_lu_59,25690112,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[6272, 1, 1]","[512, 1, 1]",122625,122625,"[64, 1024, 14, 14]","[64, 1024, 14, 14]",0.0,0.0
783,conv2d_43,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",133376,450945,"[64, 1024, 14, 14]","[64, 512, 14, 14]",524288.0,6576668672.0
784,conv2d_43,19791872,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 512]","[256, 1, 1]",65057,450945,"[64, 1024, 14, 14]","[64, 512, 14, 14]",524288.0,6576668672.0
785,conv2d_43,19791872,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_kernel,"[4, 98, 1]","[128, 1, 1]",252512,450945,"[64, 1024, 14, 14]","[64, 512, 14, 14]",524288.0,6576668672.0
786,batch_norm_43,12847104,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 32, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)","[512, 1, 1]","[512, 1, 1]",113889,113889,"[64, 512, 14, 14]","[64, 512, 14, 14]",2048.0,12845056.0
787,re_lu_60,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",59584,59584,"[64, 512, 14, 14]","[64, 512, 14, 14]",0.0,0.0
788,conv2d_44,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 16, 64]","[256, 1, 1]",67936,373921,"[64, 512, 14, 14]","[64, 512, 7, 7]",2359296.0,7398752256.0
789,conv2d_44,10387456,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",40736,373921,"[64, 512, 14, 14]","[64, 512, 7, 7]",2359296.0,7398752256.0
790,conv2d_44,10387456,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 1, 1]","[128, 1, 1]",247105,373921,"[64, 512, 14, 14]","[64, 512, 7, 7]",2359296.0,7398752256.0
791,conv2d_44,10387456,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18144,373921,"[64, 512, 14, 14]","[64, 512, 7, 7]",2359296.0,7398752256.0
792,batch_norm_44,3213312,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",26592,26592,"[64, 512, 7, 7]","[64, 512, 7, 7]",2048.0,3211264.0
793,re_lu_61,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[784, 1, 1]","[512, 1, 1]",11680,11680,"[64, 512, 7, 7]","[64, 512, 7, 7]",0.0,0.0
794,conv2d_45,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",13825,340705,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
795,conv2d_45,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",126944,340705,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
796,conv2d_45,9076736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 4, 1]","[128, 1, 1]",132864,340705,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
797,conv2d_45,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",67072,340705,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
798,batch_norm_45,12853248,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",105984,105984,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",8192.0,12845056.0
799,conv2d_46,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[7, 32, 64]","[256, 1, 1]",126881,679906,"[64, 1024, 14, 14]","[64, 2048, 7, 7]",2097152.0,6576668672.0
800,conv2d_46,21364736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 32, 2048]","[256, 1, 1]",245952,679906,"[64, 1024, 14, 14]","[64, 2048, 7, 7]",2097152.0,6576668672.0
801,conv2d_46,21364736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 4, 1]","[128, 1, 1]",240961,679906,"[64, 1024, 14, 14]","[64, 2048, 7, 7]",2097152.0,6576668672.0
802,conv2d_46,21364736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66112,679906,"[64, 1024, 14, 14]","[64, 2048, 7, 7]",2097152.0,6576668672.0
803,batch_norm_46,12853248,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",107553,107553,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",8192.0,12845056.0
804,re_lu_64,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",63072,63072,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",0.0,0.0
805,conv2d_47,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",67712,341345,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
806,conv2d_47,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 64, 512]","[256, 1, 1]",124833,341345,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
807,conv2d_47,9076736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 1, 1]","[128, 1, 1]",130560,341345,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
808,conv2d_47,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18240,341345,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
809,batch_norm_47,3213312,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",26592,26592,"[64, 512, 7, 7]","[64, 512, 7, 7]",2048.0,3211264.0
810,re_lu_65,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[784, 1, 1]","[512, 1, 1]",11744,11744,"[64, 512, 7, 7]","[64, 512, 7, 7]",0.0,0.0
811,conv2d_48,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",13888,298561,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
812,conv2d_48,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",40992,298561,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
813,conv2d_48,5570560,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 1, 1]","[128, 1, 1]",225825,298561,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
814,conv2d_48,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17856,298561,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
815,batch_norm_48,3213312,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",25440,25440,"[64, 512, 7, 7]","[64, 512, 7, 7]",2048.0,3211264.0
816,re_lu_66,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[784, 1, 1]","[512, 1, 1]",11104,11104,"[64, 512, 7, 7]","[64, 512, 7, 7]",0.0,0.0
817,conv2d_49,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",14432,341089,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
818,conv2d_49,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",127041,341089,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
819,conv2d_49,9076736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 4, 1]","[128, 1, 1]",133216,341089,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
820,conv2d_49,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66400,341089,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
821,batch_norm_49,12853248,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",105921,105921,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",8192.0,12845056.0
822,re_lu_68,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",62944,62944,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",0.0,0.0
823,conv2d_50,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",68545,343170,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
824,conv2d_50,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 64, 512]","[256, 1, 1]",124577,343170,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
825,conv2d_50,9076736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 1, 1]","[128, 1, 1]",131424,343170,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
826,conv2d_50,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",18624,343170,"[64, 2048, 7, 7]","[64, 512, 7, 7]",1048576.0,3288334336.0
827,batch_norm_50,3213312,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",27009,27009,"[64, 512, 7, 7]","[64, 512, 7, 7]",2048.0,3211264.0
828,re_lu_69,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[784, 1, 1]","[512, 1, 1]",11551,11551,"[64, 512, 7, 7]","[64, 512, 7, 7]",0.0,0.0
829,conv2d_51,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",13920,297281,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
830,conv2d_51,5570560,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 512]","[256, 1, 1]",40608,297281,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
831,conv2d_51,5570560,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 1, 1]","[128, 1, 1]",225473,297281,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
832,conv2d_51,5570560,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",17280,297281,"[64, 512, 7, 7]","[64, 512, 7, 7]",2359296.0,7398752256.0
833,batch_norm_51,3213312,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[512, 1, 1]","[512, 1, 1]",25504,25504,"[64, 512, 7, 7]","[64, 512, 7, 7]",2048.0,3211264.0
834,re_lu_70,3211264,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[784, 1, 1]","[512, 1, 1]",11424,11424,"[64, 512, 7, 7]","[64, 512, 7, 7]",0.0,0.0
835,conv2d_52,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[2, 16, 64]","[256, 1, 1]",13760,339489,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
836,conv2d_52,9076736,"void cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)","[1, 16, 2048]","[256, 1, 1]",126624,339489,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
837,conv2d_52,9076736,void cutlass_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x128_16x4::Params),"[100, 4, 1]","[128, 1, 1]",132545,339489,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
838,conv2d_52,9076736,"void cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)","[2, 64, 64]","[256, 1, 1]",66560,339489,"[64, 512, 7, 7]","[64, 2048, 7, 7]",1048576.0,3288334336.0
839,batch_norm_52,12853248,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)","[2048, 1, 1]","[512, 1, 1]",106720,106720,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",8192.0,12845056.0
840,re_lu_72,12845056,"void paddle::operators::ElementVectorizeKernel<float, float, paddle::operators::CudaReluFunctor<float>, 1, 4>(paddle::framework::Array<float const* restrict, 1>, float*, int, paddle::operators::CudaReluFunctor<float>)","[3136, 1, 1]","[512, 1, 1]",61536,61536,"[64, 2048, 7, 7]","[64, 2048, 7, 7]",0.0,0.0
841,adaptive_avg_pool2d_0,6553600,"void paddle::operators::ReduceAnyKernel<float, float, float, paddle::operators::CustomMean<float, float>, paddle::operators::kernel_primitives::details::DivideFunctor<float>, paddle::operators::LastDimIndexCal>(float const*, float*, paddle::operators::CustomMean<float, float>, paddle::operators::kernel_primitives::details::DivideFunctor<float>, float, int, int, bool, paddle::operators::LastDimIndexCal, paddle::operators::LastDimIndexCal)","[32768, 1, 1]","[32, 4, 1]",83264,83264,"[64, 2048, 7, 7]","[64, 2048, 1, 1]",0.0,6553600.0
842,linear_0,2244072,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_32x3_nn_align4>(cutlass_80_tensorop_s1688gemm_128x128_32x3_nn_align4::Params),"[8, 1, 6]","[128, 1, 1]",20257,25889,"[64, 2048]","[64, 1000]",2049000.0,131072000.0
843,linear_0,2244072,"void splitKreduce_kernel<float, float, float, float, true, false>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, void*, long, float*, int*)","[32, 4, 1]","[32, 16, 1]",5632,25889,"[64, 2048]","[64, 1000]",2049000.0,131072000.0
